{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1w1cEF4QIfwZ78Y1jR0QZB2flC5LK26rx",
      "authorship_tag": "ABX9TyP7Q+vr6lx0XKhhXYDKA6Oq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melkatewabe10/Machine-learning_LST-Estimation-/blob/main/RF_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RF_model**"
      ],
      "metadata": {
        "id": "IcEwaONQx-qL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "!pip install joblib\n",
        "!pip install scikit-learn\n",
        "!pip install scipy\n",
        "!pip install fiona"
      ],
      "metadata": {
        "id": "6HK5cQqKmTbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba64a8ed-a5c7-4d82-f0ce-de5fb4708ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.4.26)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.2.1)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (2.0.2)\n",
            "Collecting fiona\n",
            "  Downloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from fiona) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from fiona) (2025.4.26)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.11/dist-packages (from fiona) (8.2.1)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.11/dist-packages (from fiona) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from fiona) (0.7.2)\n",
            "Downloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fiona\n",
            "Successfully installed fiona-1.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seasonal  model traninig"
      ],
      "metadata": {
        "id": "nWpWPXwfjmQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from collections import OrderedDict\n",
        "\n",
        "# ===================================\n",
        "# Configuration\n",
        "# ===================================\n",
        "data_folder = '/content/drive/MyDrive/NEW FOLDER/NEWTRANING'  # <-- Update as needed\n",
        "output_folder = '/content/drive/MyDrive/NEW FOLDER/MODEL'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "years = list(range(2017, 2025))  # Extend as needed\n",
        "seasons = [f\"{s:02d}\" for s in range(1, 5)]  # '01' to '04'\n",
        "predictor_names = ['NDVI', 'EVI', 'NDWI','LAI', 'ALB', 'ELV', 'SLP', 'DSR']\n",
        "\n",
        "# ===================================\n",
        "# Helper Function to Read Raster\n",
        "# ===================================\n",
        "def read_raster(raster_path):\n",
        "    with rasterio.open(raster_path) as src:\n",
        "        return src.read(1)\n",
        "\n",
        "# ===================================\n",
        "# Store All Results\n",
        "# ===================================\n",
        "results_list = []\n",
        "\n",
        "# ===================================\n",
        "# Main Loop over Years and Seasons\n",
        "# ===================================\n",
        "for year in years:\n",
        "    for season in seasons:\n",
        "        label = f\"{year}_{season}\"\n",
        "        print(f\"\\nProcessing {label}...\")\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 1: Load Predictors\n",
        "        # --------------------------\n",
        "        predictors = OrderedDict()\n",
        "        missing = False\n",
        "        for var in predictor_names:\n",
        "            path = os.path.join(data_folder, f\"{var}_{label}.tif\")\n",
        "            if not os.path.exists(path):\n",
        "                print(f\"Missing file: {path}. Skipping {label}.\")\n",
        "                missing = True\n",
        "                break\n",
        "            predictors[var] = read_raster(path)\n",
        "        if missing:\n",
        "            continue\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 2: Load LST\n",
        "        # --------------------------\n",
        "        lst_path = os.path.join(data_folder, f\"LST_{label}.tif\")\n",
        "        if not os.path.exists(lst_path):\n",
        "            print(f\"Missing LST file: {lst_path}. Skipping {label}.\")\n",
        "            continue\n",
        "        lst = read_raster(lst_path)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 3: Stack Predictors and Target\n",
        "        # --------------------------\n",
        "        feature_stack = np.vstack([predictors[var].flatten() for var in predictor_names]).T\n",
        "        lst_flat = lst.flatten()\n",
        "\n",
        "        # Filter valid pixels\n",
        "        valid_mask = np.isfinite(feature_stack).all(axis=1) & np.isfinite(lst_flat)\n",
        "        X = feature_stack[valid_mask]\n",
        "        y = lst_flat[valid_mask]\n",
        "\n",
        "        if len(y) < 100:\n",
        "            print(f\"Too few valid pixels ({len(y)}). Skipping {label}.\")\n",
        "            continue\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 4: Define Bagging-Based Random Forest\n",
        "        # --------------------------\n",
        "        model = RandomForestRegressor(\n",
        "            n_estimators=200,\n",
        "            max_features=3,\n",
        "            min_samples_split=2,\n",
        "            max_depth=None,\n",
        "            bootstrap=True,\n",
        "            oob_score=True,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 5: Train Model\n",
        "        # --------------------------\n",
        "        print(f\"Training Random Forest for {label}...\")\n",
        "        start = time.time()\n",
        "        model.fit(X, y)\n",
        "        elapsed = time.time() - start\n",
        "        print(f\"Training complete in {elapsed:.2f} seconds.\")\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 6: Evaluate Model\n",
        "        # --------------------------\n",
        "        y_pred = model.predict(X)\n",
        "        mr2 = r2_score(y, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
        "        mae = mean_absolute_error(y, y_pred)\n",
        "        oob = model.oob_score_\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 7: Save Model\n",
        "        # --------------------------\n",
        "        model_file = os.path.join(output_folder, f\"RF_{label}.pkl\")\n",
        "        joblib.dump(model, model_file)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 8: Save Feature Importances\n",
        "        # --------------------------\n",
        "        importance_df = pd.DataFrame({\n",
        "            'Feature': predictor_names,\n",
        "            'Importance': model.feature_importances_\n",
        "        })\n",
        "        importance_file = os.path.join(output_folder, f\"Importance_{label}.csv\")\n",
        "        importance_df.to_csv(importance_file, index=False)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 9: Save R² for Each Predictor Using Linear Regression\n",
        "        # --------------------------\n",
        "        r2_data = []\n",
        "        for i, var in enumerate(predictor_names):\n",
        "            X_pred = X[:, i].reshape(-1, 1)\n",
        "            model_lr = LinearRegression()\n",
        "            model_lr.fit(X_pred, y)\n",
        "            r2 = model_lr.score(X_pred, y)\n",
        "            r2_data.append({'Feature': var, 'R2': r2})\n",
        "\n",
        "        r2_df = pd.DataFrame(r2_data)\n",
        "        r2_file = os.path.join(output_folder, f\"R2_{label}.csv\")\n",
        "        r2_df.to_csv(r2_file, index=False)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 10: Save Summary Metrics\n",
        "        # --------------------------\n",
        "        results_list.append({\n",
        "            'Year': year,\n",
        "            'Season': season,\n",
        "            'OOB_Score': oob,\n",
        "            'R2': mr2,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'Train_Time_sec': elapsed\n",
        "        })\n",
        "\n",
        "# ===================================\n",
        "# Final Summary CSV\n",
        "# ===================================\n",
        "summary_df = pd.DataFrame(results_list)\n",
        "summary_file = os.path.join(output_folder, \"Summary_Seasonal_Results.csv\")\n",
        "summary_df.to_csv(summary_file, index=False)\n",
        "\n",
        "print(\"\\nSeasonal model training completed. Summary saved to:\")\n",
        "print(summary_file)\n"
      ],
      "metadata": {
        "id": "n_vs_Ovek-ln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba13b058-9a94-4568-85f3-b7e2e8a044eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing 2017_01...\n",
            "Training Random Forest for 2017_01...\n",
            "Training complete in 23.17 seconds.\n",
            "\n",
            "Processing 2017_02...\n",
            "Training Random Forest for 2017_02...\n",
            "Training complete in 24.73 seconds.\n",
            "\n",
            "Processing 2017_03...\n",
            "Training Random Forest for 2017_03...\n",
            "Training complete in 25.21 seconds.\n",
            "\n",
            "Processing 2017_04...\n",
            "Training Random Forest for 2017_04...\n",
            "Training complete in 25.22 seconds.\n",
            "\n",
            "Processing 2018_01...\n",
            "Training Random Forest for 2018_01...\n",
            "Training complete in 26.71 seconds.\n",
            "\n",
            "Processing 2018_02...\n",
            "Training Random Forest for 2018_02...\n",
            "Training complete in 25.39 seconds.\n",
            "\n",
            "Processing 2018_03...\n",
            "Training Random Forest for 2018_03...\n",
            "Training complete in 25.84 seconds.\n",
            "\n",
            "Processing 2018_04...\n",
            "Training Random Forest for 2018_04...\n",
            "Training complete in 26.57 seconds.\n",
            "\n",
            "Processing 2019_01...\n",
            "Training Random Forest for 2019_01...\n",
            "Training complete in 26.39 seconds.\n",
            "\n",
            "Processing 2019_02...\n",
            "Training Random Forest for 2019_02...\n",
            "Training complete in 26.63 seconds.\n",
            "\n",
            "Processing 2019_03...\n",
            "Training Random Forest for 2019_03...\n",
            "Training complete in 24.89 seconds.\n",
            "\n",
            "Processing 2019_04...\n",
            "Training Random Forest for 2019_04...\n",
            "Training complete in 25.44 seconds.\n",
            "\n",
            "Processing 2020_01...\n",
            "Training Random Forest for 2020_01...\n",
            "Training complete in 26.49 seconds.\n",
            "\n",
            "Processing 2020_02...\n",
            "Training Random Forest for 2020_02...\n",
            "Training complete in 26.74 seconds.\n",
            "\n",
            "Processing 2020_03...\n",
            "Training Random Forest for 2020_03...\n",
            "Training complete in 26.20 seconds.\n",
            "\n",
            "Processing 2020_04...\n",
            "Training Random Forest for 2020_04...\n",
            "Training complete in 27.07 seconds.\n",
            "\n",
            "Processing 2021_01...\n",
            "Training Random Forest for 2021_01...\n",
            "Training complete in 26.18 seconds.\n",
            "\n",
            "Processing 2021_02...\n",
            "Training Random Forest for 2021_02...\n",
            "Training complete in 25.29 seconds.\n",
            "\n",
            "Processing 2021_03...\n",
            "Training Random Forest for 2021_03...\n",
            "Training complete in 26.69 seconds.\n",
            "\n",
            "Processing 2021_04...\n",
            "Training Random Forest for 2021_04...\n",
            "Training complete in 26.56 seconds.\n",
            "\n",
            "Processing 2022_01...\n",
            "Training Random Forest for 2022_01...\n",
            "Training complete in 26.38 seconds.\n",
            "\n",
            "Processing 2022_02...\n",
            "Training Random Forest for 2022_02...\n",
            "Training complete in 26.03 seconds.\n",
            "\n",
            "Processing 2022_03...\n",
            "Training Random Forest for 2022_03...\n",
            "Training complete in 26.34 seconds.\n",
            "\n",
            "Processing 2022_04...\n",
            "Training Random Forest for 2022_04...\n",
            "Training complete in 27.06 seconds.\n",
            "\n",
            "Processing 2023_01...\n",
            "Training Random Forest for 2023_01...\n",
            "Training complete in 27.07 seconds.\n",
            "\n",
            "Processing 2023_02...\n",
            "Training Random Forest for 2023_02...\n",
            "Training complete in 26.78 seconds.\n",
            "\n",
            "Processing 2023_03...\n",
            "Training Random Forest for 2023_03...\n",
            "Training complete in 26.89 seconds.\n",
            "\n",
            "Processing 2023_04...\n",
            "Training Random Forest for 2023_04...\n",
            "Training complete in 26.07 seconds.\n",
            "\n",
            "Processing 2024_01...\n",
            "Training Random Forest for 2024_01...\n",
            "Training complete in 27.27 seconds.\n",
            "\n",
            "Processing 2024_02...\n",
            "Training Random Forest for 2024_02...\n",
            "Training complete in 27.10 seconds.\n",
            "\n",
            "Processing 2024_03...\n",
            "Training Random Forest for 2024_03...\n",
            "Training complete in 25.54 seconds.\n",
            "\n",
            "Processing 2024_04...\n",
            "Training Random Forest for 2024_04...\n",
            "Training complete in 27.51 seconds.\n",
            "\n",
            "Seasonal model training completed. Summary saved to:\n",
            "/content/drive/MyDrive/NEW FOLDER/MODEL/Summary_Seasonal_Results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature importance csv file"
      ],
      "metadata": {
        "id": "AZnkIk7G6hyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# ========== CONFIGURATION ==========\n",
        "folder = '/content/drive/MyDrive/NEW FOLDER/MODEL'  # <- Update this path\n",
        "output_folder= '/content/drive/MyDrive/NEW FOLDER/STAT'\n",
        "output_csv = os.path.join(output_folder, 'Importanc_01.csv')\n",
        "\n",
        "# ========== SCAN AND FILTER FILES ==========\n",
        "all_files = [\n",
        "    f for f in os.listdir(folder)\n",
        "    if f.startswith(\"Importance_\") and f.endswith(\".csv\")\n",
        "]\n",
        "\n",
        "# ========== PROCESS AND COMBINE ==========\n",
        "df_list = []\n",
        "\n",
        "for file in all_files:\n",
        "    try:\n",
        "        # Extract year and season code from filename\n",
        "        parts = file.replace('.csv', '').split('_')\n",
        "        year = int(parts[1])\n",
        "        season_code = parts[2].zfill(2)  # Make sure it's '01', '02', etc.\n",
        "\n",
        "        # Read the file\n",
        "        file_path = os.path.join(folder, file)\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Add metadata\n",
        "        df['Year'] = year\n",
        "        df['Season_Code'] = season_code\n",
        "\n",
        "        df_list.append(df)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file}: {e}\")\n",
        "\n",
        "# ========== FINAL CONCATENATION ==========\n",
        "if df_list:\n",
        "    combined_df = pd.concat(df_list, ignore_index=True)\n",
        "    combined_df.to_csv(output_csv, index=False)\n",
        "    print(f\"✅ Combined seasonal importance saved to:\\n{output_csv}\")\n",
        "else:\n",
        "    print(\"No importance files were found or processed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I0VC3Sd8FyK",
        "outputId": "ab22d8f8-aa6c-4939-d74c-e74945b7158c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Combined seasonal importance saved to:\n",
            "/content/drive/MyDrive/SEASON_STAT/Importanc_03.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# R2_csv_Data"
      ],
      "metadata": {
        "id": "WvPtQys59mfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# ========== CONFIGURATION ==========\n",
        "folder = '/content/drive/MyDrive/SEASON_DATA_MODEL'  # <- Update this path\n",
        "output_folder= '/content/drive/MyDrive/SEASON_STAT'\n",
        "output_csv = os.path.join(output_folder, 'Rsquare_03.csv')\n",
        "\n",
        "# ========== SCAN AND FILTER FILES ==========\n",
        "all_files = [\n",
        "    f for f in os.listdir(folder)\n",
        "    if f.startswith(\"R2_\") and f.endswith(\".csv\")\n",
        "]\n",
        "\n",
        "# ========== PROCESS AND COMBINE ==========\n",
        "df_list = []\n",
        "\n",
        "for file in all_files:\n",
        "    try:\n",
        "        # Extract year and season code from filename\n",
        "        parts = file.replace('.csv', '').split('_')\n",
        "        year = int(parts[1])\n",
        "        season_code = parts[2].zfill(2)  # Make sure it's '01', '02', etc.\n",
        "\n",
        "        # Read the file\n",
        "        file_path = os.path.join(folder, file)\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Add metadata\n",
        "        df['Year'] = year\n",
        "        df['Season_Code'] = season_code\n",
        "\n",
        "        df_list.append(df)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file}: {e}\")\n",
        "\n",
        "# ========== FINAL CONCATENATION ==========\n",
        "if df_list:\n",
        "    combined_df = pd.concat(df_list, ignore_index=True)\n",
        "    combined_df.to_csv(output_csv, index=False)\n",
        "    print(f\"Combined seasonal importance saved to:\\n{output_csv}\")\n",
        "else:\n",
        "    print(\"No R2 files were found or processed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5UpIEMd88sh",
        "outputId": "9b4beb97-3ed9-431c-ffae-f58aa3d2ebd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined seasonal importance saved to:\n",
            "/content/drive/MyDrive/SEASON_STAT/Rsquare_03.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Monthly prediction"
      ],
      "metadata": {
        "id": "A7fbi_SOjPNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.stats import pearsonr\n",
        "from collections import OrderedDict\n",
        "\n",
        "# ===================================\n",
        "# Configuration\n",
        "# ===================================\n",
        "data_folder = '/content/drive/MyDrive/MMASK_FIVE'  # <-- Update as needed\n",
        "output_folder = '/content/drive/MyDrive/MMASK_FIVE_DD3'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "years = list(range(2021, 2022))\n",
        "months = [f\"{m:02d}\" for m in range(1, 13)]  # '01' to '12'\n",
        "predictor_names = ['NDVI', 'EVI', 'NDWI', 'LAI', 'ALB', 'ELV', 'SLP', 'DSR']\n",
        "\n",
        "# ===================================\n",
        "# Helper Function to Read Raster\n",
        "# ===================================\n",
        "def read_raster(raster_path):\n",
        "    with rasterio.open(raster_path) as src:\n",
        "        return src.read(1)\n",
        "\n",
        "# ===================================\n",
        "# Store All Results\n",
        "# ===================================\n",
        "results_list = []\n",
        "\n",
        "# ===================================\n",
        "# Main Loop over Years and Months\n",
        "# ===================================\n",
        "for year in years:\n",
        "    for month in months:\n",
        "        label = f\"{year}_{month}\"\n",
        "        print(f\"\\nProcessing {label}...\")\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 1: Load Predictors\n",
        "        # --------------------------\n",
        "        predictors = OrderedDict()\n",
        "        missing = False\n",
        "        for var in predictor_names:\n",
        "            path = os.path.join(data_folder, f\"{var}_{label}.tif\")\n",
        "            if not os.path.exists(path):\n",
        "                print(f\"Missing file: {path}. Skipping {label}.\")\n",
        "                missing = True\n",
        "                break\n",
        "            predictors[var] = read_raster(path)\n",
        "        if missing:\n",
        "            continue\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 2: Load LST\n",
        "        # --------------------------\n",
        "        lst_path = os.path.join(data_folder, f\"LST_{label}.tif\")\n",
        "        if not os.path.exists(lst_path):\n",
        "            print(f\"Missing LST file: {lst_path}. Skipping {label}.\")\n",
        "            continue\n",
        "        lst = read_raster(lst_path)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 3: Stack Predictors and Target\n",
        "        # --------------------------\n",
        "        feature_stack = np.vstack([predictors[var].flatten() for var in predictor_names]).T\n",
        "        lst_flat = lst.flatten()\n",
        "\n",
        "        # Filter valid pixels\n",
        "        valid_mask = np.isfinite(feature_stack).all(axis=1) & np.isfinite(lst_flat)\n",
        "        X = feature_stack[valid_mask]\n",
        "        y = lst_flat[valid_mask]\n",
        "\n",
        "        if len(y) < 100:\n",
        "            print(f\"Too few valid pixels ({len(y)}). Skipping {label}.\")\n",
        "            continue\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 4: Define Bagging-Based Random Forest\n",
        "        # --------------------------\n",
        "        model = RandomForestRegressor(\n",
        "            n_estimators=200,\n",
        "            max_features=3,\n",
        "            min_samples_split=2,\n",
        "            max_depth=None,\n",
        "            bootstrap=True,\n",
        "            oob_score=True,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 5: Train Model\n",
        "        # --------------------------\n",
        "        print(f\"Training Random Forest for {label}...\")\n",
        "        start = time.time()\n",
        "        model.fit(X, y)\n",
        "        elapsed = time.time() - start\n",
        "        print(f\"Training complete in {elapsed:.2f} seconds.\")\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 6: Evaluate Model\n",
        "        # --------------------------\n",
        "        y_pred = model.predict(X)\n",
        "        mr2 = r2_score(y, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
        "        mae = mean_absolute_error(y, y_pred)\n",
        "        oob = model.oob_score_\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 7: Save Model\n",
        "        # --------------------------\n",
        "        model_file = os.path.join(output_folder, f\"RF_{label}.pkl\")\n",
        "        joblib.dump(model, model_file)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 8: Save Feature Importances\n",
        "        # --------------------------\n",
        "        importance_df = pd.DataFrame({\n",
        "            'Feature': predictor_names,\n",
        "            'Importance': model.feature_importances_\n",
        "        })\n",
        "        importance_file = os.path.join(output_folder, f\"Importance_{label}.csv\")\n",
        "        importance_df.to_csv(importance_file, index=False)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 9: Save R² for Each Predictor Using Linear Regression\n",
        "        # --------------------------\n",
        "        r2_data = []\n",
        "        for i, var in enumerate(predictor_names):\n",
        "            # Reshape the predictor to be 2D as required by LinearRegression\n",
        "            X_pred = X[:, i].reshape(-1, 1)\n",
        "\n",
        "            # Fit a simple linear regression model between the predictor and the target\n",
        "            model_lr = LinearRegression()\n",
        "            model_lr.fit(X_pred, y)\n",
        "\n",
        "            # Calculate R² for this predictor\n",
        "            r2 = model_lr.score(X_pred, y)\n",
        "            r2_data.append({'Feature': var, 'R2': r2})\n",
        "\n",
        "        r2_df = pd.DataFrame(r2_data)\n",
        "        r2_file = os.path.join(output_folder, f\"R2_{label}.csv\")\n",
        "        r2_df.to_csv(r2_file, index=False)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 10: Save Summary Metrics\n",
        "        # --------------------------\n",
        "        results_list.append({\n",
        "            'Year': year,\n",
        "            'Month': month,\n",
        "            'OOB_Score': oob,\n",
        "            'R2': mr2,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'Train_Time_sec': elapsed\n",
        "        })\n",
        "\n",
        "# ===================================\n",
        "# Final Summary CSV\n",
        "# ===================================\n",
        "summary_df = pd.DataFrame(results_list)\n",
        "summary_file = os.path.join(output_folder, \"Summary_Monthly_Results.csv\")\n",
        "summary_df.to_csv(summary_file, index=False)\n",
        "\n",
        "print(\"\\nMonthly model training completed. Summary saved to:\")\n",
        "print(summary_file)\n"
      ],
      "metadata": {
        "id": "3XjJoBcXkKtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# based on data exploration"
      ],
      "metadata": {
        "id": "w96q1s1sB7Sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "!pip install joblib\n",
        "!pip install scikit-learn\n",
        "!pip install scipy\n",
        "!pip install fiona"
      ],
      "metadata": {
        "id": "zMjLRDFoCM2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Import Necessary Libraries\n",
        "# =============================================================================\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import rasterio\n",
        "import fiona\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "from rasterio.plot import show\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from scipy.stats import pearsonr\n",
        "from rasterio.mask import mask\n",
        "# Additional libraries for visualization and file operations\n",
        "from collections import OrderedDict\n",
        "\n",
        "# ===================================\n",
        "# Configuration\n",
        "# ===================================\n",
        "data_folder = '/content/drive/MyDrive/MONTHLY_THREE'  # <-- Update as needed\n",
        "output_folder = '/content/drive/MyDrive/MMASK_THREE_R22'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "years = list(range(2011, 2012))\n",
        "months = [f\"{m:02d}\" for m in range(1, 13)]  # '01' to '12'\n",
        "predictor_names = ['NDVI', 'EVI', 'NDWI', 'LAI', 'ALB', 'ELV', 'SLP', 'DSR']\n",
        "\n",
        "# ===================================\n",
        "# Helper Function to Read Raster\n",
        "# ===================================\n",
        "def read_raster(raster_path):\n",
        "    with rasterio.open(raster_path) as src:\n",
        "        return src.read(1)\n",
        "\n",
        "# ===================================\n",
        "# Store All Results\n",
        "# ===================================\n",
        "results_list = []\n",
        "\n",
        "# ===================================\n",
        "# Main Loop over Years and Months\n",
        "# ===================================\n",
        "for year in years:\n",
        "    for month in months:\n",
        "        label = f\"{year}_{month}\"\n",
        "        print(f\"\\nProcessing {label}...\")\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 1: Load Predictors\n",
        "        # --------------------------\n",
        "        predictors = OrderedDict()\n",
        "        missing = False\n",
        "        for var in predictor_names:\n",
        "            path = os.path.join(data_folder, f\"{var}_{label}.tif\")\n",
        "            if not os.path.exists(path):\n",
        "                print(f\"Missing file: {path}. Skipping {label}.\")\n",
        "                missing = True\n",
        "                break\n",
        "            predictors[var] = read_raster(path)\n",
        "        if missing:\n",
        "            continue\n",
        "\n",
        "        # --------------------------\n",
        "        # Optional: Inspect Predictor Data\n",
        "        # --------------------------\n",
        "        print(f\"Predictor statistics for {label}:\")\n",
        "        for var_name, data in predictors.items():\n",
        "            valid_data = data[np.isfinite(data)]\n",
        "            if valid_data.size == 0:\n",
        "                print(f\"{var_name}: All values are NaN. Skipping visualization.\")\n",
        "                continue\n",
        "            print(f\"{var_name}: min={np.min(valid_data):.2f}, max={np.max(valid_data):.2f}, mean={np.mean(valid_data):.2f}\")\n",
        "\n",
        "            # # Optional: Plot thumbnails\n",
        "            # plt.figure(figsize=(3, 3))\n",
        "            # plt.imshow(data, cmap='viridis')\n",
        "            # plt.colorbar(label=var_name)\n",
        "            # plt.title(f\"{var_name} - {label}\")\n",
        "            # plt.axis('off')\n",
        "            # plt.tight_layout()\n",
        "            # plt.show()\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 2: Load LST\n",
        "        # --------------------------\n",
        "        lst_path = os.path.join(data_folder, f\"LST_{label}.tif\")\n",
        "        if not os.path.exists(lst_path):\n",
        "            print(f\"Missing LST file: {lst_path}. Skipping {label}.\")\n",
        "            continue\n",
        "        lst = read_raster(lst_path)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 3: Stack Predictors and Target\n",
        "        # --------------------------\n",
        "        feature_stack = np.vstack([predictors[var].flatten() for var in predictor_names]).T\n",
        "        lst_flat = lst.flatten()\n",
        "\n",
        "        # Filter valid pixels\n",
        "        valid_mask = np.isfinite(feature_stack).all(axis=1) & np.isfinite(lst_flat)\n",
        "        X = feature_stack[valid_mask]\n",
        "        y = lst_flat[valid_mask]\n",
        "\n",
        "        if len(y) < 100:\n",
        "            print(f\"Too few valid pixels ({len(y)}). Skipping {label}.\")\n",
        "            continue\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 4: Define Bagging-Based Random Forest\n",
        "        # --------------------------\n",
        "        model = RandomForestRegressor(\n",
        "            n_estimators=500,\n",
        "            max_features=\"log2\",\n",
        "            min_samples_split=5,\n",
        "            max_depth=10,\n",
        "            min_samples_leaf=4,\n",
        "            bootstrap=True,\n",
        "            oob_score=True,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 5: Train Model\n",
        "        # --------------------------\n",
        "        print(f\"Training Random Forest for {label}...\")\n",
        "        start = time.time()\n",
        "        model.fit(X, y)\n",
        "        elapsed = time.time() - start\n",
        "        print(f\"Training complete in {elapsed:.2f} seconds.\")\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 6: Evaluate Model\n",
        "        # --------------------------\n",
        "        y_pred = model.predict(X)\n",
        "        r2 = r2_score(y, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
        "        mae = mean_absolute_error(y, y_pred)\n",
        "        oob = model.oob_score_\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 7: Save Model\n",
        "        # --------------------------\n",
        "        model_file = os.path.join(output_folder, f\"RF_{label}.pkl\")\n",
        "        joblib.dump(model, model_file)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 8: Save Feature Importances\n",
        "        # --------------------------\n",
        "        importance_df = pd.DataFrame({\n",
        "            'Feature': predictor_names,\n",
        "            'Importance': model.feature_importances_\n",
        "        })\n",
        "        importance_file = os.path.join(output_folder, f\"Importance_{label}.csv\")\n",
        "        importance_df.to_csv(importance_file, index=False)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 9: Save Pearson Correlations\n",
        "        # --------------------------\n",
        "        corr_data = []\n",
        "        for i, var in enumerate(predictor_names):\n",
        "            corr, _ = pearsonr(X[:, i], y)\n",
        "            corr_data.append({'Feature': var, 'PearsonR': corr})\n",
        "        corr_df = pd.DataFrame(corr_data)\n",
        "        corr_file = os.path.join(output_folder, f\"Correlation_{label}.csv\")\n",
        "        corr_df.to_csv(corr_file, index=False)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 10: Save Summary Metrics\n",
        "        # --------------------------\n",
        "        results_list.append({\n",
        "            'Year': year,\n",
        "            'Month': month,\n",
        "            'OOB_Score': oob,\n",
        "            'R2': r2,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'Train_Time_sec': elapsed\n",
        "        })\n",
        "\n",
        "# ===================================\n",
        "# Final Summary CSV\n",
        "# ===================================\n",
        "summary_df = pd.DataFrame(results_list)\n",
        "summary_file = os.path.join(output_folder, \"Summary_Monthly_Results.csv\")\n",
        "summary_df.to_csv(summary_file, index=False)\n",
        "\n",
        "print(\"\\nMonthly model training completed. Summary saved to:\")\n",
        "print(summary_file)\n"
      ],
      "metadata": {
        "id": "wO72k5I-BLEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seasonal prediction"
      ],
      "metadata": {
        "id": "aUJELBXXf0xO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-xMLlrQBh4C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from scipy.stats import pearsonr\n",
        "from collections import OrderedDict\n",
        "\n",
        "# ===================================\n",
        "# Configuration\n",
        "# ===================================\n",
        "data_folder = '/content/drive/MyDrive/Taiwan/'  # Change to your actual path\n",
        "output_folder = '/content/drive/MyDrive/Model_Results'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "seasons = ['Spring', 'Summer', 'Autumn', 'Winter']\n",
        "years = list(range(2000, 2026))\n",
        "predictor_names = ['NDVI', 'EVI', 'NDWI', 'LAI', 'ALB', 'ELV', 'SLP', 'DSR']\n",
        "\n",
        "# ===================================\n",
        "# Helper Function to Read Raster\n",
        "# ===================================\n",
        "def read_raster(raster_path):\n",
        "    with rasterio.open(raster_path) as src:\n",
        "        data = src.read(1)\n",
        "        return data\n",
        "\n",
        "# ===================================\n",
        "# Store All Results\n",
        "# ===================================\n",
        "results_list = []\n",
        "\n",
        "# ===================================\n",
        "# Main Loop over Years and Seasons\n",
        "# ===================================\n",
        "for year in years:\n",
        "    for season in seasons:\n",
        "        print(f\"\\nProcessing {year}_{season}...\")\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 1: Load Predictor Rasters\n",
        "        # --------------------------\n",
        "        predictors = OrderedDict()\n",
        "        missing = False\n",
        "        for var in predictor_names:\n",
        "            path = os.path.join(data_folder, f\"{var}_{year}_{season}.tif\")\n",
        "            if not os.path.exists(path):\n",
        "                print(f\"Missing file: {path}. Skipping {year}_{season}.\")\n",
        "                missing = True\n",
        "                break\n",
        "            predictors[var] = read_raster(path)\n",
        "        if missing:\n",
        "            continue\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 2: Load LST Raster\n",
        "        # --------------------------\n",
        "        lst_path = os.path.join(data_folder, f\"LST_{year}_{season}.tif\")\n",
        "        if not os.path.exists(lst_path):\n",
        "            print(f\"Missing LST file: {lst_path}. Skipping {year}_{season}.\")\n",
        "            continue\n",
        "        lst = read_raster(lst_path)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 3: Stack Predictors and Target\n",
        "        # --------------------------\n",
        "        feature_stack = np.vstack([predictors[var].flatten() for var in predictor_names]).T\n",
        "        lst_flat = lst.flatten()\n",
        "\n",
        "        # Filter valid pixels\n",
        "        valid_mask = np.isfinite(feature_stack).all(axis=1) & np.isfinite(lst_flat)\n",
        "        X = feature_stack[valid_mask]\n",
        "        y = lst_flat[valid_mask]\n",
        "\n",
        "        if len(y) < 100:\n",
        "            print(f\"Too few valid pixels ({len(y)}). Skipping {year}_{season}.\")\n",
        "            continue\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 4: Define Bagging-Based Random Forest\n",
        "        # --------------------------\n",
        "        model = RandomForestRegressor(\n",
        "            n_estimators=500,\n",
        "            max_features=\"log2\",\n",
        "            min_samples_split=5,\n",
        "            max_depth=10,\n",
        "            min_samples_leaf=4,\n",
        "            bootstrap=True,\n",
        "            oob_score=True,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 5: Train Model\n",
        "        # --------------------------\n",
        "        print(f\"Training Random Forest for {year}_{season}...\")\n",
        "        start = time.time()\n",
        "        model.fit(X, y)\n",
        "        elapsed = time.time() - start\n",
        "        print(f\"Training complete in {elapsed:.2f} seconds.\")\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 6: Evaluate Model\n",
        "        # --------------------------\n",
        "        y_pred = model.predict(X)\n",
        "        r2 = r2_score(y, y_pred)\n",
        "        rmse = mean_squared_error(y, y_pred, squared=False)\n",
        "        mae = mean_absolute_error(y, y_pred)\n",
        "        oob = model.oob_score_\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 7: Save Model\n",
        "        # --------------------------\n",
        "        model_file = os.path.join(output_folder, f\"RF_{year}_{season}.pkl\")\n",
        "        joblib.dump(model, model_file)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 8: Save Feature Importances\n",
        "        # --------------------------\n",
        "        importance_df = pd.DataFrame({\n",
        "            'Feature': predictor_names,\n",
        "            'Importance': model.feature_importances_\n",
        "        })\n",
        "        importance_file = os.path.join(output_folder, f\"Importance_{year}_{season}.csv\")\n",
        "        importance_df.to_csv(importance_file, index=False)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 9: Save Pearson Correlations\n",
        "        # --------------------------\n",
        "        corr_data = []\n",
        "        for i, var in enumerate(predictor_names):\n",
        "            corr, _ = pearsonr(X[:, i], y)\n",
        "            corr_data.append({'Feature': var, 'PearsonR': corr})\n",
        "        corr_df = pd.DataFrame(corr_data)\n",
        "        corr_file = os.path.join(output_folder, f\"Correlation_{year}_{season}.csv\")\n",
        "        corr_df.to_csv(corr_file, index=False)\n",
        "\n",
        "        # --------------------------\n",
        "        # Step 10: Save Metrics\n",
        "        # --------------------------\n",
        "        results_list.append({\n",
        "            'Year': year,\n",
        "            'Season': season,\n",
        "            'OOB_Score': oob,\n",
        "            'R2': r2,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'Train_Time_sec': elapsed\n",
        "        })\n",
        "\n",
        "# ===================================\n",
        "# Final Summary CSV\n",
        "# ===================================\n",
        "summary_df = pd.DataFrame(results_list)\n",
        "summary_file = os.path.join(output_folder, \"Summary_All_Results.csv\")\n",
        "summary_df.to_csv(summary_file, index=False)\n",
        "\n",
        "print(\"\\nAll training and saving completed. Summary saved to:\")\n",
        "print(summary_file)\n",
        "\n"
      ]
    }
  ]
}