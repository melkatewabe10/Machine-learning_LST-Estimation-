{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19wM6DY6Pk5C83pbJKR-lACUhmGyOYMCL",
      "authorship_tag": "ABX9TyMRNDSmtU8nFgooaoQwGKkt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melkatewabe10/Machine-learning_LST-Estimation-/blob/main/SWAT_Calculation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Index calcualations and conversion**"
      ],
      "metadata": {
        "id": "uApHyC_Truv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "!pip install rioxarray"
      ],
      "metadata": {
        "id": "RqeUtBCjbv3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data conversion: NetCDF to tif"
      ],
      "metadata": {
        "id": "gP4IwRqUgr0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import rioxarray as rio\n",
        "import rasterio\n",
        "import os\n",
        "\n",
        "# -------------------- CONFIGURATION --------------------\n",
        "file_path = '/content/drive/MyDrive/NEW DEMO/median2016_2022.nc'\n",
        "reference_tif_path = '/content/drive/MyDrive/NEW FOLDER/NEWTRANING/ALB_2001_01.tif'\n",
        "output_dir = '/content/drive/MyDrive/NEW FOLDER/TVPDI' # Define an output directory\n",
        "\n",
        "# -------------------- LOAD DATA --------------------\n",
        "ds = xr.open_dataset(file_path)\n",
        "\n",
        "# Rename lat/lon to y/x if needed\n",
        "ds = ds.rename({'lat': 'y', 'lon': 'x'})\n",
        "\n",
        "# Extract 'rain' variable\n",
        "rain = ds['rain']\n",
        "\n",
        "# Set spatial dimensions for rioxarray\n",
        "rain = rain.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\")\n",
        "rain = rain.rio.write_crs(\"EPSG:4326\")  # WGS84\n",
        "\n",
        "# -------------------- READ REFERENCE TIF --------------------\n",
        "with rasterio.open(reference_tif_path) as ref:\n",
        "    ref_crs = ref.crs\n",
        "    ref_transform = ref.transform\n",
        "    ref_shape = (ref.height, ref.width)\n",
        "\n",
        "# -------------------- CREATE OUTPUT DIR --------------------\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create the output directory\n",
        "\n",
        "# -------------------- LOOP THROUGH 4D DATA --------------------\n",
        "for year in rain['year'].values:\n",
        "    for season in rain['season'].values:\n",
        "        # Extract 2D slice\n",
        "        slice_2d = rain.sel(year=year, season=season)\n",
        "\n",
        "        # Reproject to match reference\n",
        "        reprojected = slice_2d.rio.reproject(\n",
        "            dst_crs=ref_crs,\n",
        "            transform=ref_transform,\n",
        "            shape=ref_shape,\n",
        "            resampling=rasterio.enums.Resampling.bilinear\n",
        "        )\n",
        "\n",
        "        # Save as GeoTIFF\n",
        "        output_filename = f\"prepmd_{year}_{season}.tif\"\n",
        "        output_path = os.path.join(output_dir, output_filename) # Changed to output_dir\n",
        "        reprojected.rio.to_raster(output_path, compress='LZW')\n",
        "\n",
        "        print(f\"âœ… Saved: {output_path}\")\n",
        "\n",
        "print(\"ðŸŽ‰ Done converting all slices.\")"
      ],
      "metadata": {
        "id": "FHl14p5H3Ic6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Z_score outlier mask method"
      ],
      "metadata": {
        "id": "FSjUDZkutp-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def mask_outliers_zscore(data, threshold=3.0):\n",
        "    \"\"\"\n",
        "    Apply Z-score masking to remove outliers in raster data.\n",
        "    Pixels with |Z| > threshold are set to NaN.\n",
        "    \"\"\"\n",
        "    mean = np.nanmean(data)\n",
        "    std = np.nanstd(data)\n",
        "\n",
        "    if std == 0 or np.isnan(std):\n",
        "        raise ValueError(\"Standard deviation is zero or NaN. Cannot compute Z-score.\")\n",
        "\n",
        "    z_scores = (data - mean) / std\n",
        "    mask = np.abs(z_scores) > threshold\n",
        "    masked_data = np.where(mask, np.nan, data)\n",
        "\n",
        "    return masked_data, mask\n",
        "\n",
        "def process_single_raster(input_path, output_path, mask_path=None, threshold=3.0, show_hist=False):\n",
        "    \"\"\"\n",
        "    Process a single raster file with Z-score masking.\n",
        "    Saves both masked output and optional mask file.\n",
        "    \"\"\"\n",
        "    with rasterio.open(input_path) as src:\n",
        "        data = src.read(1).astype(float)\n",
        "        profile = src.profile\n",
        "\n",
        "    masked_data, outlier_mask = mask_outliers_zscore(data, threshold=threshold)\n",
        "\n",
        "    profile.update(dtype='float32', nodata=np.nan)\n",
        "\n",
        "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
        "        dst.write(masked_data.astype(np.float32), 1)\n",
        "\n",
        "    if mask_path:\n",
        "        with rasterio.open(mask_path, 'w', **profile) as dst:\n",
        "            dst.write(outlier_mask.astype(np.uint8), 1)\n",
        "\n",
        "    if show_hist:\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.hist(data[~np.isnan(data)].flatten(), bins=50, color='green')\n",
        "        plt.title(f'Original NDVI: {os.path.basename(input_path)}')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.hist(masked_data[~np.isnan(masked_data)].flatten(), bins=50, color='red')\n",
        "        plt.title('Masked NDVI (Z-Score)')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def process_ndvi_files(input_folder, output_folder, mask_folder=None, threshold=3.0, show_hist=False):\n",
        "    \"\"\"\n",
        "    Batch-process only raster files starting with 'NDVI' in a folder.\n",
        "    Applies Z-score outlier masking to each.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    if mask_folder:\n",
        "        os.makedirs(mask_folder, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.tif') and filename.upper().startswith('ET'):\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "            output_path = os.path.join(input_folder, f\"masked_{filename}\")\n",
        "            mask_path = os.path.join(input_folder, f\"mask_{filename}\") if mask_folder else None\n",
        "\n",
        "            print(f\"Processing NDVI file: {filename}\")\n",
        "            try:\n",
        "                process_single_raster(input_path, output_path, mask_path, threshold, show_hist)\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Error processing {filename}: {e}\")\n",
        "\n",
        "# ======= USER PARAMETERS =======\n",
        "\n",
        "input_folder = \"/content/drive/MyDrive/NEW FOLDER/TVPDI\"\n",
        "output_folder = \"/content/drive/MyDrive/NEW FOLDER/TVPDI\"\n",
        "mask_folder = \"/content/drive/MyDrive/NEW FOLDER/TVPDI/Mask_ET\"  # Optional\n",
        "zscore_threshold = 3.0\n",
        "show_histogram = True  # Set to False to disable histogram display\n",
        "\n",
        "# ======= RUN PROCESSING =======\n",
        "\n",
        "process_ndvi_files(\n",
        "    input_folder=input_folder,\n",
        "    output_folder=output_folder,\n",
        "    mask_folder=mask_folder,\n",
        "    threshold=zscore_threshold,\n",
        "    show_hist=show_histogram\n",
        ")"
      ],
      "metadata": {
        "id": "DfI-FLYItoX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global mean based normalization"
      ],
      "metadata": {
        "id": "rC8kEcYhhC9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.enums import Resampling\n",
        "from math import sqrt\n",
        "\n",
        "# Set your input and output folders\n",
        "data_folder = '/content/drive/MyDrive/NEW FOLDER/TVPDI'\n",
        "# output_folder='/content/drive/MyDrive/NEW FOLDER/TVPDI' # Outputting to the same folder for now\n",
        "# os.makedirs(output_folder, exist_ok=True) # Ensure output directory exists\n",
        "\n",
        "# Season code mapping (remains the same)\n",
        "season_to_month = {\n",
        "    '01': '01',  # Winter\n",
        "    '02': '02',  # Spring\n",
        "    '03': '03',  # Summer\n",
        "    '04': '04'   # Autumn\n",
        "}\n",
        "\n",
        "# --- Step 1: Categorize files by season and initialize min/max for each season ---\n",
        "# Dictionary to store file paths and min/max for each season\n",
        "# Structure: {season_code: {'files': [list_of_full_paths], 'min': np.inf, 'max': -np.inf}}\n",
        "season_data = {\n",
        "    '01': {'files': [], 'min': np.inf, 'max': -np.inf}, # Winter\n",
        "    '02': {'files': [], 'min': np.inf, 'max': -np.inf}, # Spring\n",
        "    '03': {'files': [], 'min': np.inf, 'max': -np.inf}, # Summer\n",
        "    '04': {'files': [], 'min': np.inf, 'max': -np.inf}  # Autumn\n",
        "}\n",
        "\n",
        "print(\"Scanning files and categorizing by season...\")\n",
        "for filename in os.listdir(data_folder):\n",
        "    if filename.endswith('.tif') and filename.startswith('masked_ET_'):\n",
        "        parts = filename.split('_')\n",
        "        # Ensure filename has enough parts to extract season code and year\n",
        "        # Expected format: masked_NDLI_YYYY_SS.tif, so 4 parts\n",
        "        if len(parts) >= 4: # Changed from 3 to 4 to account for 'YYYY' and 'SS.tif'\n",
        "            year = parts[2] # Year is now at index 2\n",
        "            season_code = parts[3].split('.')[0] # Season code is now at index 3\n",
        "\n",
        "            if season_code in season_data:\n",
        "                input_path = os.path.join(data_folder, filename)\n",
        "                season_data[season_code]['files'].append(input_path)\n",
        "\n",
        "                # --- Step 2: Find global min and max values for each season ---\n",
        "                with rasterio.open(input_path) as src:\n",
        "                    data = src.read(1)\n",
        "                    # Mask invalid values\n",
        "                    data = np.where((data == src.nodata) | (np.isnan(data)), np.nan, data)\n",
        "\n",
        "                    # Update season-specific min and max, ignoring NaN values\n",
        "                    if not np.all(np.isnan(data)): # Only update if there's actual data\n",
        "                        local_min = np.nanmin(data)\n",
        "                        local_max = np.nanmax(data)\n",
        "                        season_data[season_code]['min'] = min(season_data[season_code]['min'], local_min)\n",
        "                        season_data[season_code]['max'] = max(season_data[season_code]['max'], local_max)\n",
        "            else:\n",
        "                print(f\"Warning: Unexpected season code '{season_code}' found in '{filename}'. Skipping.\")\n",
        "        else:\n",
        "            print(f\"Warning: Filename '{filename}' does not match expected format (e.g., masked_NDLI_YYYY_SS.tif). Skipping.\")\n",
        "\n",
        "\n",
        "print(\"\\nGlobal Min/Max values for each season:\")\n",
        "for season_code, s_data in season_data.items():\n",
        "    if s_data['files']: # Only print if there are files for this season\n",
        "        print(f\"  Season {season_code} (Month: {season_to_month.get(season_code)}):\")\n",
        "        print(f\"    Min: {s_data['min']}, Max: {s_data['max']}\")\n",
        "        if s_data['max'] == s_data['min']:\n",
        "            print(f\"    Warning: Min and Max are identical for this season. Normalization will not change values.\")\n",
        "    else:\n",
        "        print(f\"  No files found for Season {season_code}.\")\n",
        "\n",
        "\n",
        "# --- Step 3: Apply season-specific global min-max normalization to each file ---\n",
        "print(\"\\nApplying season-specific global min-max normalization to files...\")\n",
        "for season_code, s_data in season_data.items():\n",
        "    if not s_data['files']:\n",
        "        print(f\"Skipping normalization for Season {season_code} (no files).\")\n",
        "        continue\n",
        "\n",
        "    current_global_min = s_data['min']\n",
        "    current_global_max = s_data['max']\n",
        "\n",
        "    if current_global_max == current_global_min:\n",
        "        print(f\"  Warning: Global min and max are identical for Season {season_code}. Normalization will set values to 0 if min=0, otherwise it will remain unchanged where min and max are same for these files.\")\n",
        "        # We will handle this by simply writing the original data in the loop below\n",
        "        # but it's good to give a heads-up here.\n",
        "\n",
        "    for input_path in s_data['files']:\n",
        "        # Extract filename from full path for output naming\n",
        "        filename = os.path.basename(input_path)\n",
        "        print(f\"Processing: {filename}\")\n",
        "\n",
        "        parts = filename.split('_')\n",
        "        year = parts[2] # Year is at index 2\n",
        "        # season_code is already known from the outer loop\n",
        "        month_code = season_to_month.get(season_code, '00')\n",
        "\n",
        "        output_filename = f'ETn_{year}_{month_code}.tif'\n",
        "        output_path = os.path.join(data_folder, output_filename) # Output to same folder\n",
        "\n",
        "        with rasterio.open(input_path) as src:\n",
        "            profile = src.profile\n",
        "            data = src.read(1)\n",
        "\n",
        "            # Mask invalid values\n",
        "            data = np.where((data == src.nodata) | (np.isnan(data)), np.nan, data)\n",
        "\n",
        "            if current_global_max == current_global_min:\n",
        "                # If min and max are the same, result of division by zero would be NaN/inf.\n",
        "                # If the min/max is 0, normalize to 0, otherwise keep original value.\n",
        "                if current_global_min == 0:\n",
        "                    normalized_data = np.zeros_like(data, dtype=rasterio.float32)\n",
        "                    normalized_data[np.isnan(data)] = np.nan # Preserve NaNs\n",
        "                else:\n",
        "                    normalized_data = data # If min/max are same but not zero, keep original values\n",
        "            else:\n",
        "                # Apply season-specific global min-max normalization\n",
        "                normalized_data = ((data - current_global_min) / (current_global_max - current_global_min))\n",
        "                # normalized_data = normalized_data * sqrt(3) / 3 # Apply your specific scaling\n",
        "\n",
        "            # Update metadata for output\n",
        "            profile.update(\n",
        "                dtype=rasterio.float32,\n",
        "                nodata=np.nan\n",
        "            )\n",
        "\n",
        "            # Save the new image\n",
        "            with rasterio.open(output_path, 'w', **profile) as dst:\n",
        "                dst.write(normalized_data.astype(rasterio.float32), 1)\n",
        "\n",
        "        print(f\"Saved as: {output_filename}\")\n",
        "\n",
        "print(\"\\nAll files processed successfully with season-specific global min-max normalization.\")\n"
      ],
      "metadata": {
        "id": "FQ3WmDIGeJVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SWATI Vs.TVPDI Calculation"
      ],
      "metadata": {
        "id": "EfKiTCnnWPe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from math import sqrt\n",
        "\n",
        "# Set your input and output folders\n",
        "data_folder = '/content/drive/MyDrive/NEW FOLDER/SWATI'\n",
        "output_folder = '/content/drive/MyDrive/NEW FOLDER/DELETE STAT'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Season code mapping\n",
        "season_to_month = {\n",
        "    '01': '01',  # Winter\n",
        "    '02': '02',  # Spring\n",
        "    '03': '03',  # Summer\n",
        "    '04': '04'   # Autumn\n",
        "}\n",
        "\n",
        "# # Constant âˆš3/3\n",
        "SQRT3_DIV3 = sqrt(3) / 3\n",
        "\n",
        "# Loop through each Tcn file to start the processing\n",
        "for filename in sorted(os.listdir(data_folder)):\n",
        "\n",
        "    if filename.endswith('.tif') and filename.startswith('NDLIn_'):\n",
        "        print(f\"Processing: {filename}\")\n",
        "\n",
        "        # Parse year and season code from the Tcn filename\n",
        "        parts = filename.split('_')\n",
        "        year = parts[1]\n",
        "        season_code = parts[2].split('.')[0]\n",
        "        month_code = season_to_month.get(season_code, '00')  # Default '00' if missing\n",
        "\n",
        "        # Build paths for input files using \"ndli\"\n",
        "        ndli_path = os.path.join(data_folder, f'NDLIn_{year}_{season_code}.tif')\n",
        "        ndvi_path = os.path.join(data_folder, f'NDVIn_{year}_{season_code}.tif')\n",
        "        lst_path = os.path.join(data_folder, f'Tcn_{year}_{season_code}.tif')\n",
        "\n",
        "        # Check if all needed files exist\n",
        "        if not (os.path.exists(ndli_path) and os.path.exists(ndvi_path) and os.path.exists(lst_path)):\n",
        "            print(f\"  Warning: Missing ndli, NDVIn, or Tcn for {year} Season {season_code}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Open input rasters\n",
        "        with rasterio.open(ndli_path) as ndli_src, \\\n",
        "             rasterio.open(ndvi_path) as ndvi_src, \\\n",
        "             rasterio.open(lst_path) as lst_src:\n",
        "\n",
        "            ndli = ndli_src.read(1)\n",
        "            ndvi = ndvi_src.read(1)\n",
        "            lst = lst_src.read(1)\n",
        "\n",
        "            # Mask invalid values\n",
        "            ndli = np.where((ndli == ndli_src.nodata) | (np.isnan(ndli)), np.nan, ndli)\n",
        "            ndvi = np.where((ndvi == ndvi_src.nodata) | (np.isnan(ndvi)), np.nan, ndvi)\n",
        "            lst = np.where((lst == lst_src.nodata) | (np.isnan(lst)), np.nan, lst)\n",
        "\n",
        "            # Apply the SWATI formula with the 'ndli' data\n",
        "            swati = np.sqrt(\n",
        "                (SQRT3_DIV3 - ndli) ** 2 +\n",
        "                (SQRT3_DIV3 - ndvi) ** 2 +\n",
        "                (lst) ** 2\n",
        "            )\n",
        "            # swati = np.sqrt(\n",
        "            #       ((1 - ndli) ** 2 + (1 - ndvi) ** 2 + (lst) ** 2) / 3\n",
        "            #   )\n",
        "\n",
        "            # # swati = np.sqrt(\n",
        "            # #     (1 - ndli) ** 2 +\n",
        "            # #     (1 - ndvi) ** 2 +\n",
        "            # #     (lst) ** 2\n",
        "            # # )\n",
        "\n",
        "            # Save output\n",
        "            output_filename = f'SWATIl_{year}_{month_code}.tif'\n",
        "            output_path = os.path.join(output_folder, output_filename)\n",
        "\n",
        "            profile = ndli_src.profile\n",
        "            profile.update(\n",
        "                dtype=rasterio.float32,\n",
        "                nodata=np.nan\n",
        "            )\n",
        "\n",
        "            with rasterio.open(output_path, 'w', **profile) as dst:\n",
        "                dst.write(swati.astype(rasterio.float32), 1)\n",
        "\n",
        "        print(f\"  Saved SWATI file: {output_filename}\")\n",
        "\n",
        "print(\"\\nAll SWATI files processed successfully.\")"
      ],
      "metadata": {
        "id": "nmq8JTycWMX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEW SWATI Vs.TVPDI Calculation"
      ],
      "metadata": {
        "id": "EnqLmMXWzxCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from math import sqrt\n",
        "\n",
        "# --- Configuration ---\n",
        "data_folder = '/content/drive/MyDrive/NEW FOLDER/TVPDI'\n",
        "# output_folder = '/content/drive/MyDrive/NEW FOLDER/DELETE FOLDER'\n",
        "# os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Season code mapping (adjust if needed)\n",
        "season_to_month = {\n",
        "    '01': '01',\n",
        "    '02': '02',\n",
        "    '03': '03',\n",
        "    '04': '04'\n",
        "}\n",
        "\n",
        "# Ideal NDVI/NDLI value\n",
        "SQRT3_DIV3 = sqrt(3) / 3\n",
        "\n",
        "# --- Processing Loop ---\n",
        "for filename in sorted(os.listdir(data_folder)):\n",
        "    if filename.endswith('.tif') and filename.startswith('Tcn_'):\n",
        "        print(f\"Processing file: {filename}\")\n",
        "\n",
        "        # Extract year and season from filename\n",
        "        parts = filename.replace('.tif', '').split('_')\n",
        "        if len(parts) != 3:\n",
        "            print(f\"  âš ï¸ Skipping invalid filename format: {filename}\")\n",
        "            continue\n",
        "\n",
        "        year, season_code = parts[1], parts[2]\n",
        "        month_code = season_to_month.get(season_code, '00')\n",
        "\n",
        "        # Define paths to all required files\n",
        "        lst_path   = os.path.join(data_folder, f'Tcn_{year}_{season_code}.tif')\n",
        "        ndvi_path  = os.path.join(data_folder, f'NDVIn_{year}_{season_code}.tif')\n",
        "        ndli_path  = os.path.join(data_folder, f'prepn_{year}_{season_code}.tif')\n",
        "\n",
        "        # Ensure all files exist\n",
        "        if not all(map(os.path.exists, [lst_path, ndvi_path, ndli_path])):\n",
        "            print(f\" Missing files for {year} season {season_code}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # --- Read and mask raster data ---\n",
        "        with rasterio.open(lst_path) as lst_src, \\\n",
        "             rasterio.open(ndvi_path) as ndvi_src, \\\n",
        "             rasterio.open(ndli_path) as ndli_src:\n",
        "\n",
        "            # Read data\n",
        "            lst  = lst_src.read(1).astype(float)\n",
        "            ndvi = ndvi_src.read(1).astype(float)\n",
        "            ndli = ndli_src.read(1).astype(float)\n",
        "\n",
        "            # Replace nodata values with np.nan\n",
        "            lst[lst == lst_src.nodata]     = np.nan\n",
        "            ndvi[ndvi == ndvi_src.nodata]  = np.nan\n",
        "            ndli[ndli == ndli_src.nodata]  = np.nan\n",
        "\n",
        "            # Valid data mask\n",
        "            valid_mask = ~np.isnan(lst) & ~np.isnan(ndvi) & ~np.isnan(ndli)\n",
        "\n",
        "            # Initialize output with NaNs\n",
        "            swati = np.full_like(lst, np.nan, dtype=float)\n",
        "\n",
        "            # --- Compute SWATI (LST first) ---\n",
        "            swati[valid_mask] = np.sqrt(\n",
        "                (lst[valid_mask])**2 +\n",
        "                (SQRT3_DIV3 - ndvi[valid_mask])**2 +\n",
        "                (SQRT3_DIV3 - ndli[valid_mask])**2\n",
        "            )\n",
        "\n",
        "            # --- Save output raster ---\n",
        "            output_filename = f'TVPDI_{year}_{month_code}.tif'\n",
        "            output_path = os.path.join(data_folder, output_filename)\n",
        "\n",
        "            # Copy metadata and update data type/nodata\n",
        "            profile = lst_src.profile.copy()\n",
        "            profile.update(dtype=rasterio.float32, nodata=np.nan)\n",
        "\n",
        "            with rasterio.open(output_path, 'w', **profile) as dst:\n",
        "                dst.write(swati.astype(rasterio.float32), 1)\n",
        "\n",
        "            print(f\"  âœ… SWATI saved: {output_filename}\")\n",
        "\n",
        "print(\"\\nâœ… All SWATI files computed successfully.\")\n"
      ],
      "metadata": {
        "id": "4WiwUzrkzvur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TVPDI cdd based"
      ],
      "metadata": {
        "id": "SX9etovDi03G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from math import sqrt\n",
        "\n",
        "# Set your input and output folders\n",
        "data_folder = '/content/drive/MyDrive/NEW FOLDER/TVPDI'\n",
        "# output_folder = '/content/drive/MyDrive/SEASON_THREE_SWATIdd'\n",
        "# os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Season code mapping\n",
        "season_to_month = {\n",
        "    '01': '01',  # Winter (Decâ€“Feb)\n",
        "    '02': '02',  # Spring (Marâ€“May)\n",
        "    '03': '03',  # Summer (Junâ€“Aug)\n",
        "    '04': '04'   # Autumn (Sepâ€“Nov)\n",
        "}\n",
        "\n",
        "# Constant âˆš3/3\n",
        "SQRT3_DIV3 = sqrt(3) / 3\n",
        "\n",
        "# Loop through each Tcn file (trigger file)\n",
        "for filename in sorted(os.listdir(data_folder)):\n",
        "\n",
        "    if filename.endswith('.tif') and filename.startswith('Tcn_'):\n",
        "        print(f\"Processing: {filename}\")\n",
        "\n",
        "        # Parse year and season code\n",
        "        parts = filename.split('_')\n",
        "        year = parts[1]\n",
        "        season_code = parts[2].split('.')[0]\n",
        "        month_code = season_to_month.get(season_code, '00')  # Default '00' if mapping fails\n",
        "\n",
        "        # Build paths for input files\n",
        "        tcn_path = os.path.join(data_folder, f'Tcn_{year}_{season_code}.tif')\n",
        "        ndvi_path = os.path.join(data_folder, f'NDVIn_{year}_{season_code}.tif')\n",
        "        cdd_path = os.path.join(data_folder, f'cddn_{year}_{season_code}.tif')\n",
        "\n",
        "        # Check if all needed files exist\n",
        "        if not (os.path.exists(ndvi_path) and os.path.exists(cdd_path)):\n",
        "            print(f\"  Warning: Missing NDVIn or cddn for {year} Season {season_code}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Open input rasters\n",
        "        with rasterio.open(tcn_path) as tcn_src, \\\n",
        "             rasterio.open(ndvi_path) as ndvi_src, \\\n",
        "             rasterio.open(cdd_path) as cdd_src:\n",
        "\n",
        "            tcn = tcn_src.read(1)\n",
        "            ndvi = ndvi_src.read(1)\n",
        "            cdd = cdd_src.read(1)\n",
        "\n",
        "            # Mask invalid values\n",
        "            tcn = np.where((tcn == tcn_src.nodata) | (np.isnan(tcn)), np.nan, tcn)\n",
        "            ndvi = np.where((ndvi == ndvi_src.nodata) | (np.isnan(ndvi)), np.nan, ndvi)\n",
        "            cdd = np.where((cdd == cdd_src.nodata) | (np.isnan(cdd)), np.nan, cdd)\n",
        "\n",
        "            # Apply the TVPDI formula using cdd\n",
        "            tvpdi = np.sqrt(\n",
        "                (SQRT3_DIV3 - ndvi) ** 2 +\n",
        "                (cdd) ** 2 +\n",
        "                (tcn) ** 2\n",
        "            )\n",
        "\n",
        "            # Save output\n",
        "            output_filename = f'TVPDIC_{year}_{month_code}.tif'\n",
        "            output_path = os.path.join(data_folder, output_filename)\n",
        "\n",
        "            profile = tcn_src.profile\n",
        "            profile.update(\n",
        "                dtype=rasterio.float32,\n",
        "                nodata=np.nan\n",
        "            )\n",
        "\n",
        "            with rasterio.open(output_path, 'w', **profile) as dst:\n",
        "                dst.write(tvpdi.astype(rasterio.float32), 1)\n",
        "\n",
        "        print(f\"  âœ… Saved TVPDI file: {output_filename}\")\n",
        "\n",
        "print(\"\\nâœ… All TVPDI files processed successfully.\")\n"
      ],
      "metadata": {
        "id": "iQQfo5keiznq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrZdLzxO9cNp",
        "outputId": "24d73fd6-7c5f-41bb-e482-6602b525aa0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio) (2025.6.15)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio) (8.2.1)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio) (3.2.3)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1.2 cligj-0.7.2 rasterio-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Histogram plot"
      ],
      "metadata": {
        "id": "h2Upmp2UoiB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: pleasae help me to plot histogram of cddn  file in  the foldder :/content/drive/MyDrive/NEW FOLDER/TVPDI\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "import os\n",
        "\n",
        "# Define the folder containing the cddn files\n",
        "cddn_folder = '/content/drive/MyDrive/NEW FOLDER/SWATI'\n",
        "\n",
        "# List all files in the folder and filter for cddn files\n",
        "cddn_files = [f for f in os.listdir(cddn_folder) if f.startswith('NDVI_') and f.endswith('.tif')]\n",
        "\n",
        "if not cddn_files:\n",
        "    print(f\"No files starting with 'cddn_' found in {cddn_folder}\")\n",
        "else:\n",
        "    print(f\"Found {len(cddn_files)} 'cddn_' files. Plotting histograms...\")\n",
        "    # Iterate through each cddn file and plot its histogram\n",
        "    for filename in sorted(cddn_files): # Sort to process in a consistent order\n",
        "        file_path = os.path.join(cddn_folder, filename)\n",
        "        print(f\"Generating histogram for: {filename}\")\n",
        "\n",
        "        try:\n",
        "            with rasterio.open(file_path) as src:\n",
        "                data = src.read(1) # Read the first band\n",
        "\n",
        "                # Mask nodata values if present\n",
        "                if src.nodata is not None:\n",
        "                    data = np.where(data == src.nodata, np.nan, data)\n",
        "\n",
        "                # Remove NaN values before plotting histogram\n",
        "                valid_data = data[~np.isnan(data)]\n",
        "\n",
        "                if valid_data.size > 0:\n",
        "                    # Create the histogram\n",
        "                    plt.figure(figsize=(10, 6))\n",
        "                    plt.hist(valid_data.flatten(), bins=50, color='skyblue', edgecolor='black')\n",
        "                    plt.title(f'Histogram of {filename}')\n",
        "                    plt.xlabel('Pixel Value')\n",
        "                    plt.ylabel('Frequency')\n",
        "                    plt.grid(axis='y', alpha=0.75)\n",
        "                    plt.show()\n",
        "                else:\n",
        "                    print(f\"  Warning: No valid data found in {filename} to plot histogram.\")\n",
        "\n",
        "        except rasterio.errors.RasterioIOError as e:\n",
        "            print(f\"  Error opening or reading raster file {filename}: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  An unexpected error occurred while processing {filename}: {e}\")\n",
        "\n",
        "print(\"\\nHistogram plotting complete.\")\n"
      ],
      "metadata": {
        "id": "8I6HuAk3n_QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "Bv-FNkU4DgDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data exploration and checking"
      ],
      "metadata": {
        "id": "ELlWOYmFHAI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import rasterio\n",
        "from rasterio.features import shapes\n",
        "from shapely.geometry import shape\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # Import for plotting\n",
        "import seaborn as sns # Import for potentially nicer plots\n",
        "from google.colab import drive # Assuming you are running this in Google Colab\n",
        "\n",
        "# --- Configuration ---\n",
        "# !!! IMPORTANT: Update this path to your folder in Google Drive !!!\n",
        "DRIVE_FOLDER_PATH = '/content/drive/MyDrive/SEASON_DELETE2' # Updated path\n",
        "# Ensure the output directory exists or create it\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/NEW FOLDER/DELETE STAT'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "START_YEAR = 2001\n",
        "END_YEAR = 2024\n",
        "TARGET_SEASON = '02' # Season code to process\n",
        "\n",
        "# Construct output CSV name more robustly for the new data\n",
        "OUTPUT_CSV_NAME = os.path.join(OUTPUT_DIR, f'demoTcn_NDLI_NDVI_data_{TARGET_SEASON}.csv')\n",
        "\n",
        "\n",
        "# --- Helper function to get coordinates ---\n",
        "def get_coordinates(transform, rows, cols):\n",
        "    \"\"\"Calculates longitude and latitude for given rows and columns.\"\"\"\n",
        "    xs, ys = rasterio.transform.xy(transform, rows, cols)\n",
        "    # Assuming WGS84 (EPSG:4326) for lat/long.\n",
        "    # If your data is in a different CRS, you might need to reproject.\n",
        "    return xs, ys # typically longitude, latitude\n",
        "\n",
        "# --- Main Processing Logic ---\n",
        "all_pixel_data = []\n",
        "\n",
        "print(f\"Processing files from {START_YEAR} to {END_YEAR} for season {TARGET_SEASON}...\")\n",
        "\n",
        "for year in range(START_YEAR, END_YEAR + 1):\n",
        "    year_str = str(year)\n",
        "    print(f\"\\nProcessing year: {year_str}\")\n",
        "\n",
        "    # Construct file paths for the current year and target season for Tcn, NDLIn, NDVIn\n",
        "    tcn_file_pattern = os.path.join(DRIVE_FOLDER_PATH, f'TVPDICC_{year_str}_{TARGET_SEASON}*.tif')\n",
        "    ndli_file_pattern = os.path.join(DRIVE_FOLDER_PATH, f'TVPDICC_{year_str}_{TARGET_SEASON}*.tif')\n",
        "    ndvi_file_pattern = os.path.join(DRIVE_FOLDER_PATH, f'TVPDICC_{year_str}_{TARGET_SEASON}*.tif')\n",
        "\n",
        "    # Find the files - using glob to handle potential extra characters in filename if any\n",
        "    tcn_files = glob.glob(tcn_file_pattern)\n",
        "    ndli_files = glob.glob(ndli_file_pattern)\n",
        "    ndvi_files = glob.glob(ndvi_file_pattern)\n",
        "\n",
        "    # --- File Existence Checks ---\n",
        "    if not tcn_files:\n",
        "        print(f\"  Tcn file not found for {year_str}_{TARGET_SEASON}. Skipping year...\")\n",
        "        continue\n",
        "    if not ndli_files:\n",
        "        print(f\"  NDLIn file not found for {year_str}_{TARGET_SEASON}. Skipping year...\")\n",
        "        continue\n",
        "    if not ndvi_files:\n",
        "        print(f\"  NDVIn file not found for {year_str}_{TARGET_SEASON}. Skipping year...\")\n",
        "        continue\n",
        "\n",
        "    # Assuming one file per type per year/season if found\n",
        "    tcn_file_path = tcn_files[0]\n",
        "    ndli_file_path = ndli_files[0]\n",
        "    ndvi_file_path = ndvi_files[0]\n",
        "\n",
        "    print(f\"  Found Tcn:  {os.path.basename(tcn_file_path)}\")\n",
        "    print(f\"  Found NDLI: {os.path.basename(ndli_file_path)}\")\n",
        "    print(f\"  Found NDVI: {os.path.basename(ndvi_file_path)}\")\n",
        "\n",
        "\n",
        "    try:\n",
        "        with rasterio.open(tcn_file_path) as tcn_src, \\\n",
        "             rasterio.open(ndli_file_path) as ndli_src, \\\n",
        "             rasterio.open(ndvi_file_path) as ndvi_src:\n",
        "\n",
        "            # Read Tcn data and create a mask (similar to how Tsc was used)\n",
        "            tcn_data = tcn_src.read(1)\n",
        "            transform = tcn_src.transform # Get affine transform for coordinate calculation\n",
        "            nodata_val_tcn = tcn_src.nodata\n",
        "\n",
        "            # Create mask: True where data is NOT nodata and is finite\n",
        "            if nodata_val_tcn is not None:\n",
        "                mask = (tcn_data != nodata_val_tcn) & (~np.isnan(tcn_data))\n",
        "            else:\n",
        "                # If NoData value is not defined, assume all finite values are valid\n",
        "                mask = np.isfinite(tcn_data)\n",
        "\n",
        "            # Read NDLIn and NDVIn data\n",
        "            ndli_data_raw = ndli_src.read(1)\n",
        "            ndvi_data_raw = ndvi_src.read(1)\n",
        "\n",
        "            # Check if all rasters have the same shape\n",
        "            if not (tcn_data.shape == ndli_data_raw.shape == ndvi_data_raw.shape):\n",
        "                print(f\"  ERROR: Raster dimensions do not match for year {year_str}. Skipping year.\")\n",
        "                continue\n",
        "\n",
        "            # Get row and column indices of valid pixels from the Tcn mask\n",
        "            row_indices, col_indices = np.where(mask)\n",
        "\n",
        "            if row_indices.size == 0:\n",
        "                print(f\"  No valid data pixels found in Tcn for {year_str}_{TARGET_SEASON} based on the mask. Skipping year.\")\n",
        "                continue\n",
        "\n",
        "            # Get the actual values for the masked pixels\n",
        "            tcn_values = tcn_data[mask]\n",
        "            ndli_values = ndli_data_raw[mask]\n",
        "            ndvi_values = ndvi_data_raw[mask]\n",
        "\n",
        "            # Get coordinates for the masked pixels\n",
        "            longitudes, latitudes = get_coordinates(transform, row_indices, col_indices)\n",
        "\n",
        "            # Store data for this year\n",
        "            for i in range(len(longitudes)):\n",
        "                all_pixel_data.append({\n",
        "                    'lat': latitudes[i],\n",
        "                    'long': longitudes[i],\n",
        "                    'year': year,\n",
        "                    'Tcn': tcn_values[i],\n",
        "                    'NDLIn': ndli_values[i],\n",
        "                    'NDVIn': ndvi_values[i]\n",
        "                })\n",
        "            print(f\"  Processed {len(longitudes)} pixels for {year_str}_{TARGET_SEASON}.\")\n",
        "\n",
        "    except rasterio.errors.RasterioIOError as e:\n",
        "        print(f\"  Error opening one of the files for year {year_str}: {e}. Skipping year.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  An unexpected error occurred processing files for year {year_str}: {e}\")\n",
        "\n",
        "# Convert collected data to a Pandas DataFrame\n",
        "df = pd.DataFrame(all_pixel_data)\n",
        "\n",
        "# Save DataFrame to CSV\n",
        "if not df.empty:\n",
        "    # The OUTPUT_CSV_NAME is already an absolute path to the file in Drive\n",
        "    df.to_csv(OUTPUT_CSV_NAME, index=False)\n",
        "    print(f\"\\nSuccessfully extracted data and saved to: {OUTPUT_CSV_NAME}\")\n",
        "\n",
        "    # --- Grouping and Plotting ---\n",
        "    print(\"\\nStarting data aggregation and plotting...\")\n",
        "\n",
        "    # Group by year and calculate the mean for each index\n",
        "    # We will exclude 'lat' and 'long' from the mean calculation as they are coordinates\n",
        "    df_grouped_by_year = df.groupby('year')[['Tcn', 'NDLIn', 'NDVIn']].mean().reset_index()\n",
        "\n",
        "    print(\"\\nAggregated Data (Mean per Year):\")\n",
        "    print(df_grouped_by_year.head())\n",
        "\n",
        "    # Create plots for each index vs. year\n",
        "    # Define the indices you want to plot\n",
        "    indices_to_plot = ['Tcn', 'NDLIn', 'NDVIn']\n",
        "\n",
        "    for index_col in indices_to_plot:\n",
        "        plt.figure(figsize=(10, 6)) # Create a new figure for each plot\n",
        "        sns.lineplot(data=df_grouped_by_year, x='year', y=index_col, marker='o') # Line plot with markers\n",
        "        plt.title(f'Mean {index_col} Over Years (Season {TARGET_SEASON})')\n",
        "        plt.xlabel('Year')\n",
        "        plt.ylabel(f'Mean {index_col}')\n",
        "        plt.grid(True)\n",
        "        plt.xticks(df_grouped_by_year['year'].unique(), rotation=45) # Show all years on x-axis, rotate for readability\n",
        "        plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
        "\n",
        "        # Save the plot\n",
        "        plot_filename = os.path.join(OUTPUT_DIR, f'{index_col}_vs_Year_Season_{TARGET_SEASON}.png')\n",
        "        plt.savefig(plot_filename)\n",
        "        print(f\"Plot saved to: {plot_filename}\")\n",
        "        plt.show() # Display the plot\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo data was extracted. CSV file not created, and no plots will be generated.\")\n",
        "\n",
        "print(\"\\nProcessing complete.\")"
      ],
      "metadata": {
        "id": "kQ6Kn9Z8BLPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib rasterio\n",
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "_xde3k-bwl1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEMP_DATA ORGANIZATION"
      ],
      "metadata": {
        "id": "l2Mo92no_ZBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rasterio\n",
        "import numpy as np\n",
        "from rasterio.enums import Resampling\n",
        "\n",
        "# Set folders\n",
        "src_folder = \"/content/drive/MyDrive/NEW FOLDER/TVPDI2\"  # Change to your folder\n",
        "dst_folder = \"/content/drive/MyDrive/NEW FOLDER/TVPDI\"\n",
        "os.makedirs(dst_folder, exist_ok=True)\n",
        "\n",
        "# Season recoding\n",
        "season_map = {'DJF': '01', 'MAM': '02', 'JJA': '03', 'SON': '04'}\n",
        "\n",
        "# Loop through files\n",
        "for fname in os.listdir(src_folder):\n",
        "    if fname.endswith(\".tif\") and fname.startswith(\"cdd_\"):\n",
        "        parts = fname.replace(\".tif\", \"\").split(\"_\")\n",
        "        if len(parts) == 3:\n",
        "            _, year_str, season = parts\n",
        "            if season in season_map:\n",
        "                year = int(year_str)\n",
        "                if 2001 <= year <= 2022:\n",
        "                    new_name = f\"cdd_{year}_{season_map[season]}.tif\"\n",
        "                    src_path = os.path.join(src_folder, fname)\n",
        "                    dst_path = os.path.join(dst_folder, new_name)\n",
        "\n",
        "                    with rasterio.open(src_path) as src:\n",
        "                        profile = src.profile\n",
        "                        data = src.read(1).astype(np.float32)\n",
        "\n",
        "\n",
        "                        profile.update(dtype=rasterio.float32)\n",
        "\n",
        "                        with rasterio.open(dst_path, 'w', **profile) as dst:\n",
        "                            dst.write(data, 1)\n",
        "\n",
        "                    print(f\"âœ… Converted and saved: {new_name}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "nLkiuHzR_W-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation of LST: Tc,To,Ta"
      ],
      "metadata": {
        "id": "pFzYk4mF69qC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import rasterio\n",
        "from rasterio.features import shapes\n",
        "from shapely.geometry import shape\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive # Assuming you are running this in Google Colab\n",
        "\n",
        "# --- Configuration ---\n",
        "# !!! IMPORTANT: Update this path to your folder in Google Drive !!!\n",
        "DRIVE_FOLDER_PATH = '/content/drive/MyDrive/NEW FOLDER/NEWTRANING' # Example: '/content/drive/MyDrive/TemperatureData'\n",
        "# Ensure the output directory exists or create it\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/NEW FOLDER/STAT'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "START_YEAR = 2001\n",
        "END_YEAR = 2024\n",
        "TARGET_SEASON = '04' # Season code to process\n",
        "\n",
        "# Construct output CSV name more robustly\n",
        "OUTPUT_CSV_NAME = os.path.join(OUTPUT_DIR, f'TEMP_data_{TARGET_SEASON}.csv')\n",
        "\n",
        "\n",
        "# --- Helper function to get coordinates ---\n",
        "def get_coordinates(transform, rows, cols):\n",
        "    \"\"\"Calculates longitude and latitude for given rows and columns.\"\"\"\n",
        "    xs, ys = rasterio.transform.xy(transform, rows, cols)\n",
        "    # Assuming WGS84 (EPSG:4326) for lat/long.\n",
        "    # If your data is in a different CRS, you might need to reproject.\n",
        "    return xs, ys # typically longitude, latitude\n",
        "\n",
        "# --- Main Processing Logic ---\n",
        "all_pixel_data = []\n",
        "\n",
        "print(f\"Processing files from {START_YEAR} to {END_YEAR} for season {TARGET_SEASON}...\")\n",
        "\n",
        "for year in range(START_YEAR, END_YEAR + 1):\n",
        "    year_str = str(year)\n",
        "    print(f\"\\nProcessing year: {year_str}\")\n",
        "\n",
        "    # Construct file paths for the current year and target season\n",
        "    tsc_file_pattern = os.path.join(DRIVE_FOLDER_PATH, f'Tc_{year_str}_{TARGET_SEASON}*.tif')\n",
        "    tso_file_pattern = os.path.join(DRIVE_FOLDER_PATH, f'LST_{year_str}_{TARGET_SEASON}*.tif')\n",
        "    ts_file_pattern  = os.path.join(DRIVE_FOLDER_PATH, f'Ta_{year_str}_{TARGET_SEASON}*.tif') # Corrected variable name\n",
        "\n",
        "    # Find the files - using glob to handle potential extra characters in filename if any\n",
        "    tsc_files = glob.glob(tsc_file_pattern)\n",
        "    tso_files = glob.glob(tso_file_pattern)\n",
        "    ts_files  = glob.glob(ts_file_pattern)\n",
        "\n",
        "    if not tsc_files:\n",
        "        print(f\"  Tsc file not found for {year_str}_{TARGET_SEASON}. Skipping year...\")\n",
        "        continue\n",
        "    if not tso_files:\n",
        "        print(f\"  Tso file not found for {year_str}_{TARGET_SEASON}. Skipping year...\")\n",
        "        continue\n",
        "\n",
        "    # Assuming one file per type per year/season if found\n",
        "    tsc_file_path = tsc_files[0]\n",
        "    tso_file_path = tso_files[0]\n",
        "    ts_file_path = ts_files[0] if ts_files else None # Will be None if Ts file not found\n",
        "\n",
        "    print(f\"  Found Tsc: {os.path.basename(tsc_file_path)}\")\n",
        "    print(f\"  Found Tso: {os.path.basename(tso_file_path)}\")\n",
        "    if ts_file_path:\n",
        "        print(f\"  Found Ts:  {os.path.basename(ts_file_path)}\")\n",
        "    else:\n",
        "        print(f\"  Ts file not found for {year_str}_{TARGET_SEASON}. Ts_T values will be NaN.\")\n",
        "\n",
        "    try:\n",
        "        with rasterio.open(tsc_file_path) as tsc_src, \\\n",
        "             rasterio.open(tso_file_path) as tso_src:\n",
        "\n",
        "            # Read Tsc data and create a mask\n",
        "            tsc_data = tsc_src.read(1)\n",
        "            transform = tsc_src.transform # Get affine transform for coordinate calculation\n",
        "            nodata_val_tsc = tsc_src.nodata\n",
        "\n",
        "            # Create mask: True where data is NOT nodata\n",
        "            if nodata_val_tsc is not None:\n",
        "                mask = (tsc_data != nodata_val_tsc) & (~np.isnan(tsc_data))\n",
        "            else:\n",
        "                # If NoData value is not defined, assume all finite values are valid\n",
        "                mask = np.isfinite(tsc_data)\n",
        "\n",
        "            # Read Tso data\n",
        "            tso_data_raw = tso_src.read(1) # Read before shape check\n",
        "\n",
        "            # Check if Tso has the same shape as Tsc\n",
        "            if not (tsc_data.shape == tso_data_raw.shape):\n",
        "                print(f\"  ERROR: Tsc and Tso raster dimensions do not match for year {year_str}. Skipping year.\")\n",
        "                continue\n",
        "\n",
        "            ts_data_raw = None # Initialize\n",
        "            ts_temps_available = False\n",
        "\n",
        "            if ts_file_path:\n",
        "                try:\n",
        "                    with rasterio.open(ts_file_path) as ts_src:\n",
        "                        # Check if Ts has the same shape as Tsc\n",
        "                        current_ts_data = ts_src.read(1)\n",
        "                        if not (tsc_data.shape == current_ts_data.shape):\n",
        "                            print(f\"  WARNING: Ts raster dimensions ({current_ts_data.shape}) do not match Tsc ({tsc_data.shape}) for year {year_str}. Ts_T values for this year will be NaN.\")\n",
        "                        else:\n",
        "                            ts_data_raw = current_ts_data\n",
        "                            ts_temps_available = True\n",
        "                except rasterio.errors.RasterioIOError as e:\n",
        "                    print(f\"  WARNING: Could not open or read Ts file {os.path.basename(ts_file_path)} for year {year_str}: {e}. Ts_T values for this year will be NaN.\")\n",
        "            # If ts_file_path is None, ts_temps_available remains False\n",
        "\n",
        "            # Get row and column indices of valid pixels from the Tsc mask\n",
        "            row_indices, col_indices = np.where(mask)\n",
        "\n",
        "            if row_indices.size == 0:\n",
        "                print(f\"  No valid data pixels found in Tsc for {year_str}_{TARGET_SEASON} based on the mask. Skipping year.\")\n",
        "                continue\n",
        "\n",
        "            # Get the actual temperature values for the masked pixels\n",
        "            tsc_temps = tsc_data[mask]\n",
        "            tso_temps = tso_data_raw[mask] # Apply mask to Tso data\n",
        "\n",
        "            if ts_temps_available and ts_data_raw is not None:\n",
        "                ts_temps_masked = ts_data_raw[mask]\n",
        "            else:\n",
        "                # Create an array of NaNs with the same length as tsc_temps\n",
        "                # Use the same dtype as tsc_temps if it's float, otherwise default to float32 for NaNs\n",
        "                nan_dtype = tsc_temps.dtype if np.issubdtype(tsc_temps.dtype, np.floating) else np.float32\n",
        "                ts_temps_masked = np.full_like(tsc_temps, np.nan, dtype=nan_dtype)\n",
        "\n",
        "            # Get coordinates for the masked pixels\n",
        "            longitudes, latitudes = get_coordinates(transform, row_indices, col_indices)\n",
        "\n",
        "            # Store data for this year\n",
        "            for i in range(len(longitudes)):\n",
        "                all_pixel_data.append({\n",
        "                    'lat': latitudes[i],\n",
        "                    'long': longitudes[i],\n",
        "                    'year': year,\n",
        "                    'Tc': tsc_temps[i],\n",
        "                    'Tso': tso_temps[i],\n",
        "                    'Ta': ts_temps_masked[i] # This will be NaN if Ts data wasn't available/valid\n",
        "                })\n",
        "            print(f\"  Processed {len(longitudes)} pixels for {year_str}_{TARGET_SEASON}.\")\n",
        "\n",
        "    except rasterio.errors.RasterioIOError as e:\n",
        "        print(f\"  Error opening Tsc or Tso file for year {year_str}: {e}. Skipping year.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  An unexpected error occurred processing files for year {year_str}: {e}\")\n",
        "\n",
        "# Convert collected data to a Pandas DataFrame\n",
        "df = pd.DataFrame(all_pixel_data)\n",
        "\n",
        "# Save DataFrame to CSV\n",
        "if not df.empty:\n",
        "    # The OUTPUT_CSV_NAME is already an absolute path to the file in Drive\n",
        "    df.to_csv(OUTPUT_CSV_NAME, index=False)\n",
        "    print(f\"\\nSuccessfully extracted data and saved to: {OUTPUT_CSV_NAME}\")\n",
        "else:\n",
        "    print(\"\\nNo data was extracted. CSV file not created.\")\n",
        "\n",
        "print(\"\\nProcessing complete.\")"
      ],
      "metadata": {
        "id": "WkkJWSbn_T0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All_indices_data_csv export"
      ],
      "metadata": {
        "id": "t_hCJiyR2bOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from google.colab import drive # Assuming you are running this in Google Colab\n",
        "\n",
        "# --- Configuration ---\n",
        "# !!! IMPORTANT: Update paths to your data folders in Google Drive !!!\n",
        "# Path for all secondary files (TVPDIC, cdd, prep, TVPDI)\n",
        "DRIVE_FOLDER_PATH = '/content/drive/MyDrive/NEW FOLDER/TVPDI'\n",
        "\n",
        "# Path for the primary SWATI files (2001-2024)\n",
        "SWATI_FOLDER_PATH = '/content/drive/MyDrive/NEW FOLDER/SWATI'\n",
        "\n",
        "# Ensure the output directory exists or create it\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/NEW FOLDER/STAT'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "START_YEAR = 2001\n",
        "END_YEAR = 2024 # Set to 2024 to process all available SWATI files\n",
        "TARGET_SEASON = '04' # Season code to process (e.g., '01' for DJF)\n",
        "\n",
        "# --- EDITED: Updated CSV name to reflect all included files ---\n",
        "OUTPUT_CSV_NAME = os.path.join(OUTPUT_DIR, f'All_indices_{TARGET_SEASON}.csv')\n",
        "\n",
        "# --- Helper function to get coordinates (reusable) ---\n",
        "def get_coordinates(transform, rows, cols):\n",
        "    \"\"\"Calculates longitude and latitude for given rows and columns.\"\"\"\n",
        "    xs, ys = rasterio.transform.xy(transform, rows, cols)\n",
        "    return xs, ys\n",
        "\n",
        "# --- Main Processing Logic ---\n",
        "all_pixel_data = []\n",
        "\n",
        "# --- EDITED: Updated print statements to include the new TVPDI file ---\n",
        "print(f\"Processing files from {START_YEAR} to {END_YEAR} for season {TARGET_SEASON}...\")\n",
        "print(f\"Primary reference file: SWATI_YYYY_SS*.tif (from {SWATI_FOLDER_PATH})\")\n",
        "print(f\"Secondary files (2001-2022): TVPDIC_*, TVPDI_*, cdd_*, prep_* (from {DRIVE_FOLDER_PATH})\")\n",
        "print(f\"For 2023-2024, only SWATI data will be extracted; other values will be NaN.\")\n",
        "\n",
        "for year in range(START_YEAR, END_YEAR + 1):\n",
        "    year_str = str(year)\n",
        "    print(f\"\\nProcessing year: {year_str}, Season: {TARGET_SEASON}\")\n",
        "\n",
        "    # --- EDITED: Define file patterns for all five files from their respective folders ---\n",
        "    swati_file_pattern = os.path.join(SWATI_FOLDER_PATH, f'SWATI_{year_str}_{TARGET_SEASON}*.tif')\n",
        "    tvpdic_file_pattern = os.path.join(DRIVE_FOLDER_PATH, f'TVPDIC_{year_str}_{TARGET_SEASON}*.tif')\n",
        "    tvpdi_file_pattern = os.path.join(DRIVE_FOLDER_PATH, f'TVPDI_{year_str}_{TARGET_SEASON}*.tif') # Added TVPDI\n",
        "    cdd_file_pattern = os.path.join(DRIVE_FOLDER_PATH, f'cdd_{year_str}_{TARGET_SEASON}*.tif')\n",
        "    prep_file_pattern = os.path.join(DRIVE_FOLDER_PATH, f'meanr_{year_str}_{TARGET_SEASON}*.tif')\n",
        "\n",
        "    # Find files\n",
        "    swati_files = glob.glob(swati_file_pattern)\n",
        "    tvpdic_files = glob.glob(tvpdic_file_pattern)\n",
        "    tvpdi_files = glob.glob(tvpdi_file_pattern) # Find TVPDI files\n",
        "    cdd_files = glob.glob(cdd_file_pattern)\n",
        "    prep_files = glob.glob(prep_file_pattern)\n",
        "\n",
        "    # Check for primary SWATI file first\n",
        "    if not swati_files:\n",
        "        print(f\"  Primary SWATI file not found for {year_str}_{TARGET_SEASON}. Skipping year/season...\")\n",
        "        continue\n",
        "\n",
        "    swati_file_path = swati_files[0]\n",
        "    tvpdic_file_path = tvpdic_files[0] if tvpdic_files else None\n",
        "    tvpdi_file_path = tvpdi_files[0] if tvpdi_files else None # Get path for TVPDI\n",
        "    cdd_file_path = cdd_files[0] if cdd_files else None\n",
        "    prep_file_path = prep_files[0] if prep_files else None\n",
        "\n",
        "    print(f\"  Found primary SWATI: {os.path.basename(swati_file_path)}\")\n",
        "    if tvpdic_file_path:\n",
        "        print(f\"  Found TVPDIC: {os.path.basename(tvpdic_file_path)}\")\n",
        "    else:\n",
        "        print(f\"  TVPDIC file not found for {year_str}_{TARGET_SEASON}. tvpdic values will be NaN.\")\n",
        "    if tvpdi_file_path:\n",
        "        print(f\"  Found TVPDI: {os.path.basename(tvpdi_file_path)}\")\n",
        "    else:\n",
        "        print(f\"  TVPDI file not found for {year_str}_{TARGET_SEASON}. tvpdi values will be NaN.\")\n",
        "    if cdd_file_path:\n",
        "        print(f\"  Found cdd: {os.path.basename(cdd_file_path)}\")\n",
        "    else:\n",
        "        print(f\"  cdd file not found for {year_str}_{TARGET_SEASON}. cdd values will be NaN.\")\n",
        "    if prep_file_path:\n",
        "        print(f\"  Found prep: {os.path.basename(prep_file_path)}\")\n",
        "    else:\n",
        "        print(f\"  prep file not found for {year_str}_{TARGET_SEASON}. prep values will be NaN.\")\n",
        "\n",
        "    try:\n",
        "        # Open primary SWATI file to get transform, mask, etc.\n",
        "        with rasterio.open(swati_file_path) as swati_src:\n",
        "            swati_data = swati_src.read(1)\n",
        "            transform = swati_src.transform\n",
        "            nodata_val_swati = swati_src.nodata\n",
        "\n",
        "            # Create mask based on the primary SWATI data\n",
        "            if nodata_val_swati is not None:\n",
        "                mask = (swati_data != nodata_val_swati) & (~np.isnan(swati_data))\n",
        "            else:\n",
        "                mask = np.isfinite(swati_data)\n",
        "\n",
        "            # Initialize raw data variables for secondary files\n",
        "            tvpdic_data_raw = None\n",
        "            tvpdi_data_raw = None # Initialized for TVPDI\n",
        "            cdd_data_raw = None\n",
        "            prep_data_raw = None\n",
        "\n",
        "            # Process TVPDIC file\n",
        "            if tvpdic_file_path:\n",
        "                try:\n",
        "                    with rasterio.open(tvpdic_file_path) as tvpdic_src:\n",
        "                        if not (swati_data.shape == tvpdic_src.shape):\n",
        "                            print(f\"  WARNING: TVPDIC raster dimensions ({tvpdic_src.shape}) do not match primary SWATI ({swati_data.shape}). tvpdic values will be NaN.\")\n",
        "                        else:\n",
        "                            tvpdic_data_raw = tvpdic_src.read(1)\n",
        "                except rasterio.errors.RasterioIOError as e:\n",
        "                    print(f\"  WARNING: Could not open/read TVPDIC file: {e}. tvpdic values will be NaN.\")\n",
        "\n",
        "            # --- EDITED: Process TVPDI file ---\n",
        "            if tvpdi_file_path:\n",
        "                try:\n",
        "                    with rasterio.open(tvpdi_file_path) as tvpdi_src:\n",
        "                        if not (swati_data.shape == tvpdi_src.shape):\n",
        "                            print(f\"  WARNING: TVPDI raster dimensions ({tvpdi_src.shape}) do not match primary SWATI ({swati_data.shape}). tvpdi values will be NaN.\")\n",
        "                        else:\n",
        "                            tvpdi_data_raw = tvpdi_src.read(1)\n",
        "                except rasterio.errors.RasterioIOError as e:\n",
        "                    print(f\"  WARNING: Could not open/read TVPDI file: {e}. tvpdi values will be NaN.\")\n",
        "\n",
        "            # Process cdd file\n",
        "            if cdd_file_path:\n",
        "                try:\n",
        "                    with rasterio.open(cdd_file_path) as cdd_src:\n",
        "                        if not (swati_data.shape == cdd_src.shape):\n",
        "                            print(f\"  WARNING: cdd raster dimensions ({cdd_src.shape}) do not match primary SWATI ({swati_data.shape}). cdd values will be NaN.\")\n",
        "                        else:\n",
        "                            cdd_data_raw = cdd_src.read(1)\n",
        "                except rasterio.errors.RasterioIOError as e:\n",
        "                    print(f\"  WARNING: Could not open/read cdd file: {e}. cdd values will be NaN.\")\n",
        "\n",
        "            # Process prep file\n",
        "            if prep_file_path:\n",
        "                try:\n",
        "                    with rasterio.open(prep_file_path) as prep_src:\n",
        "                        if not (swati_data.shape == prep_src.shape):\n",
        "                            print(f\"  WARNING: prep raster dimensions ({prep_src.shape}) do not match primary SWATI ({swati_data.shape}). prep values will be NaN.\")\n",
        "                        else:\n",
        "                            prep_data_raw = prep_src.read(1)\n",
        "                except rasterio.errors.RasterioIOError as e:\n",
        "                    print(f\"  WARNING: Could not open/read prep file: {e}. prep values will be NaN.\")\n",
        "\n",
        "            row_indices, col_indices = np.where(mask)\n",
        "\n",
        "            if row_indices.size == 0:\n",
        "                print(f\"  No valid data pixels found in primary SWATI for {year_str}_{TARGET_SEASON}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Extract values from the primary SWATI data\n",
        "            swati_values_at_mask = swati_data[mask]\n",
        "            nan_dtype = swati_values_at_mask.dtype if np.issubdtype(swati_values_at_mask.dtype, np.floating) else np.float32\n",
        "\n",
        "            # Prepare masked arrays for all secondary files, defaulting to NaN\n",
        "            tvpdic_values_masked = np.full_like(swati_values_at_mask, np.nan, dtype=nan_dtype)\n",
        "            if tvpdic_data_raw is not None:\n",
        "                tvpdic_values_masked = tvpdic_data_raw[mask]\n",
        "\n",
        "            tvpdi_values_masked = np.full_like(swati_values_at_mask, np.nan, dtype=nan_dtype) # For TVPDI\n",
        "            if tvpdi_data_raw is not None:\n",
        "                tvpdi_values_masked = tvpdi_data_raw[mask]\n",
        "\n",
        "            cdd_values_masked = np.full_like(swati_values_at_mask, np.nan, dtype=nan_dtype)\n",
        "            if cdd_data_raw is not None:\n",
        "                cdd_values_masked = cdd_data_raw[mask]\n",
        "\n",
        "            prep_values_masked = np.full_like(swati_values_at_mask, np.nan, dtype=nan_dtype)\n",
        "            if prep_data_raw is not None:\n",
        "                prep_values_masked = prep_data_raw[mask]\n",
        "\n",
        "            longitudes, latitudes = get_coordinates(transform, row_indices, col_indices)\n",
        "\n",
        "            # --- EDITED: Append data for each valid pixel with all five data columns ---\n",
        "            for i in range(len(longitudes)):\n",
        "                all_pixel_data.append({\n",
        "                    'lat': latitudes[i],\n",
        "                    'long': longitudes[i],\n",
        "                    'year': year,\n",
        "                    'swati': swati_values_at_mask[i],\n",
        "                    'tvpdic': tvpdic_values_masked[i],\n",
        "                    'tvpdi': tvpdi_values_masked[i], # Added TVPDI data\n",
        "                    'cdd': cdd_values_masked[i],\n",
        "                    'prep': prep_values_masked[i]\n",
        "                })\n",
        "            print(f\"  Processed {len(longitudes)} pixels for {year_str}_{TARGET_SEASON}.\")\n",
        "\n",
        "    except rasterio.errors.RasterioIOError as e:\n",
        "        print(f\"  Error opening primary SWATI file {os.path.basename(swati_file_path)}: {e}. Skipping.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  An unexpected error occurred processing files for {year_str}_{TARGET_SEASON}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Create a Pandas DataFrame from the collected pixel data\n",
        "if all_pixel_data:\n",
        "    df = pd.DataFrame(all_pixel_data)\n",
        "    df.to_csv(OUTPUT_CSV_NAME, index=False)\n",
        "    print(f\"\\nSuccessfully extracted data and saved to: {OUTPUT_CSV_NAME}\")\n",
        "else:\n",
        "    print(\"\\nNo data was extracted. CSV file not created.\")\n",
        "\n",
        "print(\"\\nProcessing complete.\")"
      ],
      "metadata": {
        "id": "NfqRjXZO2VeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SWATI_mean rain_ Organization"
      ],
      "metadata": {
        "id": "GHQRkuJmljRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "src = '/content/drive/MyDrive/PREP_VALIDATION'\n",
        "dst = '/content/drive/MyDrive/NEW FOLDER/TVPDI'\n",
        "\n",
        "os.makedirs(dst, exist_ok=True)\n",
        "\n",
        "for year in range(2001, 2025):\n",
        "    for season in ['01', '02', '03', '04']:\n",
        "        file_name = f'meanr_{year}_{season}.tif'  # change extension if needed\n",
        "        src_path = os.path.join(src, file_name)\n",
        "        dst_path = os.path.join(dst, file_name)\n",
        "\n",
        "        if os.path.isfile(src_path):\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "            print(f'âœ… Copied file: {file_name}')\n",
        "        else:\n",
        "            print(f' Not found: {file_name}')\n",
        "\n"
      ],
      "metadata": {
        "id": "wRSzp66_nz0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SWATI_Cdd_ Organization"
      ],
      "metadata": {
        "id": "9NljPzF06o06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define source and destination directories\n",
        "src = '/content/drive/MyDrive/NEW FOLDER/SWATI'\n",
        "dst = '/content/drive/MyDrive/NEW FOLDER/TVPDI'\n",
        "\n",
        "# # Ensure the destination directory exists\n",
        "# os.makedirs(dst, exist_ok=True)\n",
        "\n",
        "# Seasonal mapping: from string suffix to numeric code\n",
        "season_map = {\n",
        "    '01': '01',\n",
        "    '02': '02',\n",
        "    '03': '03',\n",
        "    '04': '04'\n",
        "}\n",
        "\n",
        "# Process years and seasons\n",
        "for year in range(2001, 2025):\n",
        "    for season_str, season_code in season_map.items():\n",
        "        # Original file format\n",
        "        original_name = f'SWATI_{year}_{season_str}.tif'\n",
        "        src_path = os.path.join(src, original_name)\n",
        "\n",
        "        # Target renamed format\n",
        "        renamed_name = f'SWATI_{year}_{season_code}.tif'\n",
        "        dst_path = os.path.join(dst, renamed_name)\n",
        "\n",
        "        if os.path.isfile(src_path):\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "            print(f'âœ… Copied and renamed: {original_name} âžœ {renamed_name}')\n",
        "        else:\n",
        "            print(f'âŒ File not found: {original_name}')\n"
      ],
      "metadata": {
        "id": "E7wHvi1Y6lEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "X0P1of6OFSJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SWATI_cdd_TVPDI_prep"
      ],
      "metadata": {
        "id": "Ew7IKLLabMhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from google.colab import drive # Assuming you are running this in Google Colab\n",
        "\n",
        "# --- Configuration ---\n",
        "# !!! IMPORTANT: Update paths to your data folders in Google Drive !!!\n",
        "# Path for TVPDIC, cdd, and prep files (2001-2022)\n",
        "DRIVE_FOLDER_PATH = '/content/drive/MyDrive/NEW FOLDER/TVPDI'\n",
        "\n",
        "# Path for the primary SWATI files (2001-2024)\n",
        "SWATI_FOLDER_PATH = '/content/drive/MyDrive/NEW FOLDER/SWATI'\n",
        "\n",
        "# Ensure the output directory exists or create it\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/NEW FOLDER/STAT'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "START_YEAR = 2001\n",
        "END_YEAR = 2024 # --- EDITED: Set to 2024 to process all available SWATI files\n",
        "TARGET_SEASON = '04' # Season code to process (e.g., '01' for DJF)\n",
        "\n",
        "# Updated CSV name to reflect SWATI is the primary file\n",
        "OUTPUT_CSV_NAME = os.path.join(OUTPUT_DIR, f'SWATI_TVPDI_pcd_{TARGET_SEASON}.csv')\n",
        "\n",
        "# --- Helper function to get coordinates (reusable) ---\n",
        "def get_coordinates(transform, rows, cols):\n",
        "    \"\"\"Calculates longitude and latitude for given rows and columns.\"\"\"\n",
        "    xs, ys = rasterio.transform.xy(transform, rows, cols)\n",
        "    return xs, ys\n",
        "\n",
        "# --- Main Processing Logic ---\n",
        "all_pixel_data = []\n",
        "\n",
        "# --- EDITED: Updated print statements to reflect new logic ---\n",
        "print(f\"Processing files from {START_YEAR} to {END_YEAR} for season {TARGET_SEASON}...\")\n",
        "print(f\"Primary reference file: SWATI_YYYY_SS*.tif (from {SWATI_FOLDER_PATH})\")\n",
        "print(f\"Secondary files (2001-2022): TVPDIC_*, cdd_*, prep_* (from {DRIVE_FOLDER_PATH})\")\n",
        "print(f\"For 2023-2024, only SWATI data will be extracted; other values will be NaN.\")\n",
        "\n",
        "for year in range(START_YEAR, END_YEAR + 1):\n",
        "    year_str = str(year)\n",
        "    print(f\"\\nProcessing year: {year_str}, Season: {TARGET_SEASON}\")\n",
        "\n",
        "    # Define file patterns for all four files from their respective folders\n",
        "    swati_file_pattern = os.path.join(SWATI_FOLDER_PATH, f'SWATI2_{year_str}_{TARGET_SEASON}*.tif')\n",
        "    tvpdic_file_pattern = os.path.join(DRIVE_FOLDER_PATH, f'TVPDIC_{year_str}_{TARGET_SEASON}*.tif')\n",
        "    cdd_file_pattern = os.path.join(DRIVE_FOLDER_PATH, f'cdd_{year_str}_{TARGET_SEASON}*.tif')\n",
        "    prep_file_pattern = os.path.join(DRIVE_FOLDER_PATH, f'prep_{year_str}_{TARGET_SEASON}*.tif')\n",
        "\n",
        "    # Find files\n",
        "    swati_files = glob.glob(swati_file_pattern)\n",
        "    tvpdic_files = glob.glob(tvpdic_file_pattern)\n",
        "    cdd_files = glob.glob(cdd_file_pattern)\n",
        "    prep_files = glob.glob(prep_file_pattern)\n",
        "\n",
        "    # --- EDITED: Check for primary SWATI file first ---\n",
        "    if not swati_files:\n",
        "        print(f\"  Primary SWATI file not found for {year_str}_{TARGET_SEASON}. Skipping year/season...\")\n",
        "        continue\n",
        "\n",
        "    swati_file_path = swati_files[0]\n",
        "    tvpdic_file_path = tvpdic_files[0] if tvpdic_files else None\n",
        "    cdd_file_path = cdd_files[0] if cdd_files else None\n",
        "    prep_file_path = prep_files[0] if prep_files else None\n",
        "\n",
        "    print(f\"  Found primary SWATI: {os.path.basename(swati_file_path)}\")\n",
        "    if tvpdic_file_path:\n",
        "        print(f\"  Found TVPDIC: {os.path.basename(tvpdic_file_path)}\")\n",
        "    else:\n",
        "        print(f\"  TVPDIC file not found for {year_str}_{TARGET_SEASON}. tvpdic values will be NaN.\")\n",
        "    if cdd_file_path:\n",
        "        print(f\"  Found cdd: {os.path.basename(cdd_file_path)}\")\n",
        "    else:\n",
        "        print(f\"  cdd file not found for {year_str}_{TARGET_SEASON}. cdd values will be NaN.\")\n",
        "    if prep_file_path:\n",
        "        print(f\"  Found prep: {os.path.basename(prep_file_path)}\")\n",
        "    else:\n",
        "        print(f\"  prep file not found for {year_str}_{TARGET_SEASON}. prep values will be NaN.\")\n",
        "\n",
        "    try:\n",
        "        # --- EDITED: Open primary SWATI file to get transform, mask, etc. ---\n",
        "        with rasterio.open(swati_file_path) as swati_src:\n",
        "            swati_data = swati_src.read(1)\n",
        "            transform = swati_src.transform\n",
        "            nodata_val_swati = swati_src.nodata\n",
        "\n",
        "            # Create mask based on the primary SWATI data\n",
        "            if nodata_val_swati is not None:\n",
        "                mask = (swati_data != nodata_val_swati) & (~np.isnan(swati_data))\n",
        "            else:\n",
        "                mask = np.isfinite(swati_data)\n",
        "\n",
        "            # Initialize raw data variables for secondary files\n",
        "            tvpdic_data_raw = None\n",
        "            cdd_data_raw = None\n",
        "            prep_data_raw = None\n",
        "\n",
        "            # Process TVPDIC file\n",
        "            if tvpdic_file_path:\n",
        "                try:\n",
        "                    with rasterio.open(tvpdic_file_path) as tvpdic_src:\n",
        "                        # Check dimensions against the primary SWATI raster\n",
        "                        if not (swati_data.shape == tvpdic_src.shape):\n",
        "                            print(f\"  WARNING: TVPDIC raster dimensions ({tvpdic_src.shape}) do not match primary SWATI ({swati_data.shape}). tvpdic values will be NaN.\")\n",
        "                        else:\n",
        "                            tvpdic_data_raw = tvpdic_src.read(1)\n",
        "                except rasterio.errors.RasterioIOError as e:\n",
        "                    print(f\"  WARNING: Could not open/read TVPDIC file {os.path.basename(tvpdic_file_path)}: {e}. tvpdic values will be NaN.\")\n",
        "\n",
        "            # Process cdd file\n",
        "            if cdd_file_path:\n",
        "                try:\n",
        "                    with rasterio.open(cdd_file_path) as cdd_src:\n",
        "                        if not (swati_data.shape == cdd_src.shape):\n",
        "                            print(f\"  WARNING: cdd raster dimensions ({cdd_src.shape}) do not match primary SWATI ({swati_data.shape}). cdd values will be NaN.\")\n",
        "                        else:\n",
        "                            cdd_data_raw = cdd_src.read(1)\n",
        "                except rasterio.errors.RasterioIOError as e:\n",
        "                    print(f\"  WARNING: Could not open/read cdd file {os.path.basename(cdd_file_path)}: {e}. cdd values will be NaN.\")\n",
        "\n",
        "            # Process prep file\n",
        "            if prep_file_path:\n",
        "                try:\n",
        "                    with rasterio.open(prep_file_path) as prep_src:\n",
        "                        if not (swati_data.shape == prep_src.shape):\n",
        "                            print(f\"  WARNING: prep raster dimensions ({prep_src.shape}) do not match primary SWATI ({swati_data.shape}). prep values will be NaN.\")\n",
        "                        else:\n",
        "                            prep_data_raw = prep_src.read(1)\n",
        "                except rasterio.errors.RasterioIOError as e:\n",
        "                    print(f\"  WARNING: Could not open/read prep file {os.path.basename(prep_file_path)}: {e}. prep values will be NaN.\")\n",
        "\n",
        "            row_indices, col_indices = np.where(mask)\n",
        "\n",
        "            if row_indices.size == 0:\n",
        "                print(f\"  No valid data pixels found in primary SWATI for {year_str}_{TARGET_SEASON}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Extract values from the primary SWATI data\n",
        "            swati_values_at_mask = swati_data[mask]\n",
        "            nan_dtype = swati_values_at_mask.dtype if np.issubdtype(swati_values_at_mask.dtype, np.floating) else np.float32\n",
        "\n",
        "            # Prepare masked arrays for all secondary files, defaulting to NaN\n",
        "            tvpdic_values_masked = np.full_like(swati_values_at_mask, np.nan, dtype=nan_dtype)\n",
        "            if tvpdic_data_raw is not None:\n",
        "                tvpdic_values_masked = tvpdic_data_raw[mask]\n",
        "\n",
        "            cdd_values_masked = np.full_like(swati_values_at_mask, np.nan, dtype=nan_dtype)\n",
        "            if cdd_data_raw is not None:\n",
        "                cdd_values_masked = cdd_data_raw[mask]\n",
        "\n",
        "            prep_values_masked = np.full_like(swati_values_at_mask, np.nan, dtype=nan_dtype)\n",
        "            if prep_data_raw is not None:\n",
        "                prep_values_masked = prep_data_raw[mask]\n",
        "\n",
        "            longitudes, latitudes = get_coordinates(transform, row_indices, col_indices)\n",
        "\n",
        "            # --- EDITED: Append data for each valid pixel with new column order ---\n",
        "            for i in range(len(longitudes)):\n",
        "                all_pixel_data.append({\n",
        "                    'lat': latitudes[i],\n",
        "                    'long': longitudes[i],\n",
        "                    'year': year,\n",
        "                    'swati2': swati_values_at_mask[i],\n",
        "                    'tvpdic': tvpdic_values_masked[i],\n",
        "                    'cdd': cdd_values_masked[i],\n",
        "                    'prep': prep_values_masked[i]\n",
        "                })\n",
        "            print(f\"  Processed {len(longitudes)} pixels for {year_str}_{TARGET_SEASON}.\")\n",
        "\n",
        "    except rasterio.errors.RasterioIOError as e:\n",
        "        print(f\"  Error opening primary SWATI file {os.path.basename(swati_file_path)} for {year_str}_{TARGET_SEASON}: {e}. Skipping.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  An unexpected error occurred processing files for {year_str}_{TARGET_SEASON}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Create a Pandas DataFrame from the collected pixel data\n",
        "if all_pixel_data:\n",
        "    df = pd.DataFrame(all_pixel_data)\n",
        "    df.to_csv(OUTPUT_CSV_NAME, index=False)\n",
        "    print(f\"\\nSuccessfully extracted data and saved to: {OUTPUT_CSV_NAME}\")\n",
        "else:\n",
        "    print(\"\\nNo data was extracted. CSV file not created.\")\n",
        "\n",
        "print(\"\\nProcessing complete.\")"
      ],
      "metadata": {
        "id": "GFvZ6d7NJZvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "8hRU7PwnZ1Ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: PLEASE HELP ME TO DISPLAY ALL TVPDI MAPS AND HELP ME TO SEE\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "import os\n",
        "\n",
        "data_folder = '/content/drive/MyDrive/NEW DEMO/PREP'\n",
        "\n",
        "for filename in sorted(os.listdir(data_folder)):\n",
        "    if filename.endswith('.tif') and filename.startswith('prep_'):\n",
        "        print(f\"Displaying: {filename}\")\n",
        "        filepath = os.path.join(data_folder, filename)\n",
        "\n",
        "        with rasterio.open(filepath) as src:\n",
        "            tvpdi_data = src.read(1)\n",
        "            plt.figure(figsize=(10, 8))\n",
        "            plt.imshow(tvpdi_data, cmap='viridis')  # You can change the colormap\n",
        "            plt.colorbar(label='TVPDI')\n",
        "            plt.title(filename)\n",
        "            plt.show()\n"
      ],
      "metadata": {
        "id": "ySF9RkDfXwFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trend analysis"
      ],
      "metadata": {
        "id": "GNyGDkB659mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot rastrio :/content/drive/MyDrive/PREP_VALIDATION/rain_2021_04.tif\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "file_path = '/content/drive/MyDrive/PREP_VALIDATION/rain_2021_04.tif'\n",
        "\n",
        "try:\n",
        "    with rasterio.open(file_path) as src:\n",
        "        # Read the raster data\n",
        "        raster_data = src.read(1)  # Assuming it's a single-band image\n",
        "\n",
        "        # Check for invalid values (e.g., nodata) and handle them appropriately.\n",
        "        # For example, replace nodata values with NaN:\n",
        "        if src.nodata is not None:\n",
        "            raster_data = np.where(raster_data == src.nodata, np.nan, raster_data)\n",
        "\n",
        "        # Display the raster data using matplotlib\n",
        "        plt.imshow(raster_data, cmap='viridis') # You can change the colormap\n",
        "        plt.colorbar(label='Pixel Value')\n",
        "        plt.title(f'Raster Data from {file_path}')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "except rasterio.errors.RasterioIOError as e:\n",
        "    print(f\"Error opening or reading the raster file: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "qm41DAlUGTYY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}